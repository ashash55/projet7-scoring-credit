{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f367f2",
   "metadata": {},
   "source": [
    "# Projet 7: Impl√©mentez un mod√®le de scoring (feature selection et choix du mod√®le de scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6ded8",
   "metadata": {},
   "source": [
    "## Table des mati√®res: <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "1. [Import des librairies et configurations g√©n√©rales](#library)\n",
    "2. [Chargement des donn√©es](#load)\n",
    "3. [S√©lection des donn√©es d'entrainement et de test](#train_test)\n",
    "4. [Feature selection](#feats)\n",
    "5. [Traitement des donn√©es d√©s√©quilibr√©es](#imbalanced)\n",
    "6. [Pipeline, optimisation et entrainement des mod√®les](#pipe)\n",
    "7. [Choix des scores](#scores)\n",
    "8. [Mod√©lisations](#model)\n",
    "    1. [Mod√®le Baseline: Dummy classifier](#dummy)\n",
    "    2. [R√©gression logistique](#reglog)\n",
    "    3. [LightGBM](#lightgbm)\n",
    "9. [S√©lection du meilleur mod√®le](#best)\n",
    "    1. [D√©finition du seuil de probabilit√©](#predict_proba)\n",
    "    2. [Sauvegarde du mod√®le](#save)\n",
    "    3. [Features importance](#feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a06f6",
   "metadata": {},
   "source": [
    "## Import des librairies et configurations g√©n√©rales <a class=\"anchor\" id=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15b544",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/ashash/7/projet7-scoring-credit/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Configuration pour permettre les longues ex√©cutions\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Augmenter le timeout Jupyter pour permettre les longues ex√©cutions\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "    import IPython\n",
    "    # Configuration du kernel pour timeout tr√®s long (1 heure)\n",
    "    IPython.get_ipython().kernel.shell.run_cell(\n",
    "        \"%config IPKernelApp.iopub_data_rate_limit=1e10\"\n",
    "    )\n",
    "    print(\"‚úÖ Configuration notebook pour longues ex√©cutions activ√©e\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Configuration timeout non appliqu√©e (environnement non Jupyter)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin\n",
    "import time\n",
    "import os\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Fonctions personnelles\n",
    "import fct_eda\n",
    "import fct_preprocessing\n",
    "\n",
    "\n",
    "# Update Fonctions personnelles\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "# Balancing data\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as pipe\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, fbeta_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# Feature importance locales\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Configuration MLflow pour √©viter les erreurs de model registry\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"false\"\n",
    "\n",
    "# Enregistrement du mod√®le\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import dill\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Pandas\n",
    "pd_option_dictionary = {\n",
    "    'display.max_rows': 500,\n",
    "    'display.max_column': 200,\n",
    "    'display.width': 300,\n",
    "    'display.precision': 4,\n",
    "    'display.max_colwidth': None,\n",
    "    'display.float_format' : '{:.2f}'.format,\n",
    "}\n",
    "\n",
    "for pat, value in pd_option_dictionary.items():\n",
    "    pd.set_option(pat, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c605a",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es <a class=\"anchor\" id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6191ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fct_preprocessing.preprocessing_no_NaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification que le dataset consolid√© ne contient pas de NaN\n",
    "fct_eda.shape_total_nan(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04faf56",
   "metadata": {},
   "source": [
    "## S√©lection des donn√©es d'entrainement et de test <a class=\"anchor\" id=\"train_test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c3b69",
   "metadata": {},
   "source": [
    "En Machine Learning il ne faut jamais valider un mod√®le sur les donn√©es qui ont servi √† son entrainement. Le mod√®le doit √™tre test√© sur des donn√©es qu'il n'a jamais vues. On aura ainsi une id√©e de sa performance future. Le dataset sera m√©lang√© de fa√ßon al√©atoire avant d'√™tre divis√© en deux parties:\n",
    "- un **train set** dont les donn√©es sont utilis√©es pour **entrainer le mod√®le** (80% des donn√©es)\n",
    "- un **test set** r√©serv√© uniquement √† **l'√©valuation du mod√®le** (20% des donn√©es)\n",
    "\n",
    "La s√©paration du dataset en donn√©es d‚Äôentrainement et de test va permettre de **d√©tecter de l‚Äôoverfitting** (mod√®le trop complexe qui apprend parfaitement les donn√©es d‚Äôentrainement mais n‚Äôarrive pas √† g√©n√©raliser) ou de **l‚Äôunderfitting** (mod√®le trop simple ou mal choisi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd95e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des features et de la target\n",
    "col_X = [f for f in df.columns if f not in ['TARGET']]\n",
    "X = df_feat[col_X]\n",
    "y = df_feat['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des variables quantitatives\n",
    "num_feat = X.select_dtypes(exclude='object').columns.tolist()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder sur nos variables cat√©gorielles\n",
    "X, categ_feat = fct_eda.categories_encoder(X, nan_as_category = False)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu d'entrainement (80%) et de validation (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state = 42)\n",
    "print(f\"Nb de lignes des donn√©es d'entrainement: {len(X_train)} \\nNb de lignes des donn√©es de validation: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f16a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fbde6",
   "metadata": {},
   "source": [
    "## Feature selection <a class=\"anchor\" id=\"feats\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481200ef",
   "metadata": {},
   "source": [
    "M√™me si nous avons d√©j√† enlev√© quelques features quantitatives fortement corr√©l√©es entre elles et qualitatives en testant leur association avec la target via Chi2 et Kruskal Wallis, il reste encore beaucoup trop de variables pour les prendre toutes dans notre mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affe4a6",
   "metadata": {},
   "source": [
    "La s√©lection des caract√©ristiques est le processus de r√©duction du nombre de variables d'entr√©e lors de l'√©laboration d'un mod√®le pr√©dictif. On trouve 2 avantages principaux √† r√©duire le nombre de variables en entr√©e du mod√®le:\n",
    "- **r√©duire le co√ªt de calcul**\n",
    "- **am√©liorer la performance du mod√®le**\n",
    "\n",
    "Les m√©thodes bas√©es sur les statistiques impliquent l'√©valuation de la **relation entre chaque variable d'entr√©e et la variable cible √† l'aide de statistiques**. Les variables qui ont la relation la plus forte avec la target seront conserv√©es.\n",
    "\n",
    "Il existe 2 techniques principales de s√©lection des caract√©ristiques: **supervis√©e** et **non supervis√©e** (les caract√©ristiques seront s√©lectionn√©es en fonction de la target ou non).\n",
    "\n",
    "Les m√©thodes supervis√©es peuvent √™tre class√©es en 3 groupes\n",
    "- **intrins√®ques**: algorithmes qui effectuent une **s√©lection automatique** des caract√©ristiques pendant l'entrainement\n",
    "- **wrapper**: m√©thodes qui √©valuent plusieurs mod√®les √† l'aide de proc√©dures qui **ajoutent et/ou suppriment des pr√©dicteurs** afin de trouver la **combinaison optimale** qui **maximise la performance du mod√®le**.\n",
    "- **filtres**: s√©lectionne des sous-ensembles de caract√©ristiques en fonction de leur **relation avec la cible**.\n",
    "\n",
    "Nous allons dans un premier temps \n",
    "- supprimer les caract√©ristiques qui n'ont pas de variance c'est √† dire les variables qui n'ont qu'une seule et m√™me valeur parmis toutes les observations et n'apportent pas vraiment d'information (produit lors du OneHotEncoding)\n",
    "- faire une s√©lection des variables cat√©gorielles puis num√©riques en nous aidant de **m√©thodes statistiques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4649331",
   "metadata": {},
   "source": [
    "### VarianceThreshold <a class=\"anchor\" id=\"Variance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810a138",
   "metadata": {},
   "source": [
    "Nous allons ici supprimer les colonnes sans variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c38d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = VarianceThreshold(0)\n",
    "\n",
    "X_train_trans = transform.fit_transform(X_train)\n",
    "X_test_trans = transform.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = transform.get_support()\n",
    "feat_suppr = X.columns[~mask].tolist()\n",
    "\n",
    "print('Colonnes supprim√©es')\n",
    "feat_suppr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des variables cat√©gorielles actualis√©e\n",
    "categ_feat = [elem for elem in categ_feat if elem not in feat_suppr]\n",
    "\n",
    "# Liste des variables num√©riques actualis√©e\n",
    "num_feat = [elem for elem in num_feat if elem not in feat_suppr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a87f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveaux df\n",
    "X_train = X_train[num_feat + categ_feat]\n",
    "X_test = X_test[num_feat + categ_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b83114",
   "metadata": {},
   "source": [
    "## Fonctions utilis√©es l'or de Mod√©lisation  <a class=\"anchor\" id=\"imbalanced\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c32e7a",
   "metadata": {},
   "source": [
    "| R√©el \\ Pr√©dit          | 0                   | 1                   |\n",
    "| ---------------------- | ------------------- | ------------------- |\n",
    "| **0 (non d√©faillant)** | VN *(vrai n√©gatif)* | FP *(faux positif)* |\n",
    "| **1 (d√©faillant)**     | FN *(faux n√©gatif)* | VP *(vrai positif)* |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metier(ytest, y_pred):\n",
    "    # Matrice de confusion transform√©e en array avec affectation aux bonnes cat√©gories\n",
    "    (vn, fp, fn, vp) = confusion_matrix(ytest, y_pred).ravel()\n",
    "\n",
    "    # Rappel avec action fp ‚Üí √† minimiser\n",
    "    score_metier = 10 * fn + fp\n",
    "\n",
    "    return score_metier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b053104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(best_model, xtest, ytest, beta_value):\n",
    "    y_pred = best_model.predict(xtest)\n",
    "\n",
    "    score_biz = score_metier(ytest, y_pred)\n",
    "    betascore = fbeta_score(ytest, y_pred, beta=beta_value)\n",
    "    recall = recall_score(ytest, y_pred)\n",
    "    precision = precision_score(ytest, y_pred, zero_division=0)\n",
    "    accuracy = accuracy_score(ytest, y_pred)\n",
    "    auc = roc_auc_score(ytest, y_pred)\n",
    "\n",
    "    print(f'Score m√©tier: {score_biz}')\n",
    "    print(f'Beta score: {betascore}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'AUC: {auc}')\n",
    "\n",
    "    return score_biz, betascore, recall, precision, accuracy, auc, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651249da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, model_name=\"Mod√®le\", labels=None, save_path=None):\n",
    "  \n",
    "    if labels is None:\n",
    "        labels = ['Y=0 (Non d√©faillant)', 'Y=1 (D√©faillant)']\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm,\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                linewidths=.5,\n",
    "                cmap=sns.cubehelix_palette(as_cmap=True),\n",
    "                cbar=False)\n",
    "    plt.title(f'Matrice de confusion: {model_name}')\n",
    "    plt.ylabel('R√©alit√©')\n",
    "    plt.xlabel('Pr√©diction')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "def plot_recall_precision_threshold(model, X_test, y_test, model_name=\"Mod√®le\", beta=2, cost_fn_ratio=10):\n",
    "    \"\"\"\n",
    "    Plot precision-recall curve et calcule les seuils optimaux\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : classifier\n",
    "        Mod√®le entra√Æn√©\n",
    "    X_test : array-like\n",
    "        Features de test\n",
    "    y_test : array-like\n",
    "        Target de test\n",
    "    model_name : str\n",
    "        Nom du mod√®le pour le titre\n",
    "    beta : float\n",
    "        Param√®tre beta pour F-beta score\n",
    "    cost_fn_ratio : float\n",
    "        Ratio de co√ªt m√©tier (FN / FP)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtenir les probabilit√©s\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcul de precision et recall pour diff√©rents seuils\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    \n",
    "    # Calcul du F-beta score pour chaque seuil\n",
    "    fbeta_scores = []\n",
    "    for p, r in zip(precision, recall):\n",
    "        if (p + r) == 0:\n",
    "            fbeta_scores.append(0)\n",
    "        else:\n",
    "            f_beta = (1 + beta**2) * (p * r) / ((beta**2 * p) + r)\n",
    "            fbeta_scores.append(f_beta)\n",
    "    \n",
    "    # Calcul du score m√©tier pour chaque seuil\n",
    "    business_scores = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "        score = score_metier(y_test, y_pred_thresh)\n",
    "        business_scores.append(score)\n",
    "    \n",
    "    # Trouver les seuils optimaux\n",
    "    best_idx_fbeta = np.argmax(fbeta_scores)\n",
    "    best_threshold_fbeta = thresholds[best_idx_fbeta] if best_idx_fbeta < len(thresholds) else 0.5\n",
    "    \n",
    "    best_idx_business = np.argmin(business_scores)\n",
    "    best_threshold_business = thresholds[best_idx_business] if best_idx_business < len(thresholds) else 0.5\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Axe 1: Precision et Recall\n",
    "    ax1.plot(thresholds, precision[:-1], label='Precision', linewidth=2, color='blue')\n",
    "    ax1.plot(thresholds, recall[:-1], label='Recall', linewidth=2, color='red')\n",
    "    ax1.set_xlabel('Threshold', fontsize=11)\n",
    "    ax1.set_ylabel('Precision / Recall', fontsize=11, color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Axe 2: F-beta score\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(thresholds, fbeta_scores[:-1], label=f'F{beta}-Score', linewidth=2, color='green', linestyle='--')\n",
    "    ax2.set_ylabel(f'F{beta}-Score', fontsize=11, color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.legend(loc='center right', fontsize=10)\n",
    "    \n",
    "    # Marquer les seuils optimaux\n",
    "    ax1.axvline(best_threshold_fbeta, color='green', linestyle=':', linewidth=2, label=f'Seuil optimal F{beta}')\n",
    "    ax1.axvline(best_threshold_business, color='orange', linestyle=':', linewidth=2, label=f'Seuil optimal M√©tier')\n",
    "    \n",
    "    plt.title(f'Precision-Recall-Threshold: {model_name}', fontweight='bold', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_threshold_fbeta, best_threshold_business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6717a88",
   "metadata": {},
   "source": [
    "## Traitement des donn√©es d√©s√©quilibr√©es <a class=\"anchor\" id=\"imbalanced\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94245b6",
   "metadata": {},
   "source": [
    "Lors de l'analyse exploratoire, nous avons remarqu√© que les donn√©es √©taient tr√®s **d√©s√©quilibr√©es** entre les d√©faillants et non d√©faillants. Les non d√©faillants sont largement sur repr√©sent√©s (> 91%).\n",
    "\n",
    "La plupart des mod√®les de Machine Learning vont **ignorer la classe minoritaire** et donc avoir des **performances m√©diocres** dans cette classe alors qu'en g√©n√©ral c'est la performance de la classe minoritaire qui est la plus importante.\n",
    "\n",
    "Une des approches pour traiter les ensembles de donn√©es d√©s√©quilibr√©s consiste √† sur√©chantillonner la classe minoritaire. La m√©thode la plus simple est de **dupliquer les exemples de la classe minoritaire** m√™me si aucune information n'est ajout√©e au mod√®le.\n",
    "\n",
    "Il est √©galement possible de **pond√©rer les classes** c'est √† dire ajuster la fonction de co√ªt du mod√®le de mani√®re √† ce qu'une mauvaise classification d'une observation de la classe minoritaire soit plus lourdement p√©nalis√©e qu'une mauvaise classification d'une observation de la classe majoritaire. Cette approche contribue √† am√©liorer la pr√©cision du mod√®le en r√©√©quilibrant la distribution des classes. Comme aucun nouveau point de donn√©es n'est cr√©√©, la m√©thode doit √™te utilis√©e conjointement avec d'autres m√©thodes comme le sur√©chantillonnage par exemple.\n",
    "\n",
    "Au lieu de cela, de nouveaux **exemples peuvent √™tre synth√©tis√©s √† partir des exemples existants**. Il s'agit d'un type d'augmentation de donn√©es pour la classe minoritaire appel√© **SMOTE** pour (Synthetic Minority Oversampling Technique ou Technique de sur√©chantillonnage synth√©tique des minorit√©s).\n",
    "\n",
    "Un **exemple al√©atoire de la classe minoritaire** est choisi et les k plus proches voisins sont trouv√©s (avec k = 5 en g√©n√©ral). **Un voisin est choisi au hasard** et un segment est trac√© entre les 2 points.\n",
    " \n",
    "Il est recommand√© d'utiliser d'abord un **sous-√©chantillonnage al√©atoire** pour r√©duire le nombre d'exemples dans la classe minoritaire puis d'utiliser **SMOTE** pour sur√©chantillonner la classe minoritaire afin d'√©quilibrer la distribution des classes. C'est une approche efficace car les nouveaux exemples synth√©tiques de la classe minoritaire sont plausibles (proches dans l'espace des caract√©ristiques des exemples existants de la classe minoritaire).\n",
    "\n",
    "L'inconv√©nient g√©n√©ral serait que les exemples synth√©tiques sont cr√©√©s sans tenir compte de la classe majoritaire.\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f38783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la target\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.countplot(x = 'TARGET', data = df, palette=['green', 'red'])\n",
    "plt.title('Distribution de la target', fontweight='bold', fontsize = 12)\n",
    "x = [0, 1]\n",
    "plt.xticks(x, ['Non D√©faillant', 'D√©faillant'])\n",
    "plt.xlabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efddacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a56de1",
   "metadata": {},
   "source": [
    "## Pipeline, optimisation et entrainement des mod√®les <a class=\"anchor\" id=\"pipe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885acc30",
   "metadata": {},
   "source": [
    "Nous allons dans un premier temps cr√©er une **pipeline** pour chacun de nos mod√®les. Cette pipeline va nous permettre d'affecter des √©tapes de preprocessing √† nos donn√©es, c'est √† dire des transformations comme le traitement des donn√©es d√©s√©quilibr√©es, la standardisation de nos donn√©es, et de choisir le type de mod√®le.\n",
    "\n",
    "Cette pipeline sera ensuite int√©gr√©e dans une fonction d'optimisation et d'entrainement qui va utiliser la **validation crois√©e** pour tester la robustesse du mod√®le pr√©dictif en r√©p√©tant la proc√©dure de split. Elle donnera plusieurs erreurs d'apprentissage et de test et donc une **estimation de la variabilit√© de la performance de g√©n√©ralisation du mod√®le**. Ici, nous avons utilis√© la m√©thode **KFold** qui consiste √† d√©couper le train set en cinq parties, l'entrainer sur les quatre premi√®res parties puis le valider sur la cinqui√®me. On recommencera sur toutes les configurations possibles puis on fera la moyenne des cinq scores et on pourra donc comparer nos mod√®les pour √™tre s√ªr de prendre celui qui a en moyenne la meilleure performance.\n",
    "\n",
    "Le r√©glage des hyperparam√®tres s'effectuera soit √† l'aide du  **GridSearchCV** qui va tester toutes les combinaisons possibles d'hyperparam√®tres afin de trouver celles qui vont minimiser le plus l'erreur (m√©thode exhaustive tr√®s **co√ªteuse en termes de puissance de calcul et de temps**), soit du **RandomizedSearchCV** qui va s√©lectionner des combinaisaons al√©atoires d'hyperparam√®tres. Cette m√©thode est un peu **moins pr√©cise** mais beaucoup **plus rapide**. Elle sera utilis√©e pour les mod√®les plus complexes.\n",
    "\n",
    "Enfin, pour √©valuer la **performance r√©elle de nos mod√®les**, nous calculerons les metriques s√©lectionn√©es sur les donn√©es de test.\n",
    "\n",
    "La validation crois√©e peut √™tre utilis√©e √† la fois pour le **r√©glage des hyperparam√®tres** et pour l'estimation de la **performance de g√©n√©ralisation** d'un mod√®le. Cependant, l'utiliser √† ces deux fins en m√™me temps est probl√©matique. Le r√©glage des hyperparam√®tres est une forme d'apprentissage automatique et, par cons√©quent, nous avons besoin d'une **autre boucle externe de validation crois√©e** pour √©valuer correctement la performance de g√©n√©ralisation de la proc√©dure de mod√©lisation compl√®te. Lorsque l'on optimise certaines parties de la pipeline d'apprentissage automatique (par exemple, les hyperparam√®tres, la transformation, etc.), il est n√©cessaire d'utiliser la **nested cross validation** pour √©valuer la performance de g√©n√©ralisation du mod√®le pr√©dictif. Sinon, les r√©sultats obtenus sans nested cross validation sont souvent trop optimistes.  C‚Äôest ce qui a √©t√© fait pour visualiser la distribution de la m√©trique s√©lectionn√©e sur les donn√©es d‚Äôentrainement et de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d108aa8",
   "metadata": {},
   "source": [
    "## Choix des scores <a class=\"anchor\" id=\"scores\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9456b",
   "metadata": {},
   "source": [
    "Si l'on se r√©f√®re au fichier de description des colonnes:\n",
    "- **1** => clients a des difficult√©s de paiement, il a eu un retard de paiement de plus de X jours sur au moins une des Y premi√®res √©ch√©ances du pr√™t dans notre √©chantillon (**d√©faillant**)\n",
    "- **0** => tous les autres cas (**non d√©faillant**)\n",
    "\n",
    "Sur une matrice de confusion, les d√©faillants repr√©sentent la classe positive (Y=1) et les non d√©faillants la classe n√©gative (Y=0).\n",
    "\n",
    "Comme il serait extr√™ment co√ªteux pour la banque d'accorder un cr√©dit √† un client d√©faillant qui ne le rembourserait pas ou en partie, il nous faut **minimiser le nombre de faux n√©gatifs** c'est √† dire un client pr√©dit non d√©faillant alors qu'il est d√©faillant.\n",
    "\n",
    "Il faut √©galement t√¢cher de **minimiser les faux positifs** c'est √† dire pr√©dire qu'un client est d√©faillant alors qu'il ne l'est pas (risque de perte de clients, de manque √† gagner).\n",
    "\n",
    "Cependant, un faux positif n'a pas le m√™me co√ªt qu'un faux n√©gatif. Ce dernier est beaucoup plus co√ªteux pour la banque. **Nous accorderons donc 10 fois plus de poids aux faux n√©gatifs** (fonction co√ªt m√©tier). \n",
    "\n",
    "Le **Rappel (Recall)** qui mesure le taux de vrais positifs est √† favoriser au d√©triment de la pr√©cision qui est la capacit√© du classificateur √† ne pas √©tiqueter comme positif un √©chantillon qui est n√©gatif.\n",
    "\n",
    "Pour faire cela, nous allons nous baser sur le **F-beta score** qui est la moyenne harmonique pond√©r√©e de la pr√©cision et du rappel. Le param√®tre b√™ta d√©termine le poids du rappel dans le score. Lorsqu'il est supp√©rieur √† un, il favorise le rappel. Nous testerons plusieurs valeurs pour le beta et garderons celui qui donne le meilleur score.\n",
    "\n",
    "Nous mettrons √©galement l'**accuracy** et l'**AUC** comme √©l√©ments de comparaison. Le **temps d'entrainement** sera √©galement track√©.\n",
    "\n",
    "Le choix du meilleur mod√®le se fera via **cross validation sur le betascore** puis sur les donn√©es de test en fonction du **score m√©tier et du betascore**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ee64b",
   "metadata": {},
   "source": [
    "## Mod√©lisations <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb80fb",
   "metadata": {},
   "source": [
    "Nous cherchons √† classer les demandes en **cr√©dit accord√© ou refus√©**. Il s'agit donc d'un mod√®le de **classification binaire**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a7355",
   "metadata": {},
   "source": [
    "### Mod√®le Baseline: Dummy classifier <a class=\"anchor\" id=\"dummy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a51e5",
   "metadata": {},
   "source": [
    "Ce classificateur fait des pr√©dictions en utilisant des r√®gles simples. Il est utile comme **base de r√©f√©rence simple** √† comparer avec d'autres classificateurs et ne sera pas optimis√©. Il ignore les variables en entr√©e et par cons√©quent, n'utilise aucune information provenant des features. Il n'y a donc **pas besoin de transformer au pr√©alable nos features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4158e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy classifier baseline model\n",
    "# On renomme l'instance pour coh√©rence: dummy_clf\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DUMMY CLASSIFIER BASELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Evaluate metrics\n",
    "score_biz, betascore, recall, precision, accuracy, auc, y_pred = eval_metrics(dummy_clf, X_test, y_test, beta_value=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de la matrice de confusion avec la fonction d√©finie plus haut\n",
    "plot_confusion_matrix(y_test, y_pred_dummy, model_name=\"DummyClassifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2a81d",
   "metadata": {},
   "source": [
    "### Mod√®le Baseline: Regression Logistic <a class=\"anchor\" id=\"dummy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7a0b6",
   "metadata": {},
   "source": [
    "La **r√©gression logistique** est un mod√®le de classification binaire qui estime la probabilit√© qu'une observation appartienne √† une classe en utilisant la fonction logistique (sigmo√Øde). \n",
    "\n",
    "**Avantages:**\n",
    "- Simple, interpr√©table et rapide √† entra√Æner\n",
    "- Probabilit√©s calibr√©es\n",
    "- Performances solides sur donn√©es lin√©airement s√©parables\n",
    "\n",
    "**Strat√©gie:**\n",
    "Nous allons tester **toutes les strat√©gies de r√©√©quilibrage** disponibles pour identifier celle qui offre les meilleures performances:\n",
    "1. **Sans r√©√©quilibrage** (baseline)\n",
    "2. **Class weight balanced** (pond√©ration des classes)\n",
    "3. **SMOTE 0.5** (sur√©chantillonnage synth√©tique avec ratio 0.5)\n",
    "4. **SMOTE 0.7** (sur√©chantillonnage synth√©tique avec ratio 0.7)\n",
    "5. **Undersample 0.5** (sous-√©chantillonnage al√©atoire avec ratio 0.5)\n",
    "6. **Combine** (undersample + SMOTE combin√©)\n",
    "\n",
    "Pour chaque strat√©gie, nous optimiserons les hyperparam√®tres avec RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74783239",
   "metadata": {},
   "source": [
    "#### Configuration et pr√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aea9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration flexible du GridSearch - √Ä AJUSTER selon vos besoins\n",
    "GRIDSEARCH_CONFIG = {\n",
    "    'cv_splits': 2,           # R√©duit √† 2 pour rapidit√©\n",
    "    'cv_repeats': 1,          # 1 repeat\n",
    "    'use_randomized': True,   # Utiliser RandomizedSearchCV au lieu de GridSearchCV\n",
    "    'n_iter': 1,              # UNE SEULE it√©ration (grille d√©j√† simplifi√©e)\n",
    "    'verbose': 1              # 0=silencieux, 1=peu de texte, 2=d√©taill√©\n",
    "}\n",
    "\n",
    "# D√©finition des strat√©gies de r√©√©quilibrage √† tester (r√©duites √† essentielles)\n",
    "balancing_strategies = {\n",
    "    'none': {'strategy': 'none', 'sampling_ratio': None},\n",
    "    'class_weight': {'strategy': 'class_weight', 'sampling_ratio': None},\n",
    "    'smote_0.5': {'strategy': 'smote', 'sampling_ratio': 0.5},\n",
    "    'smote_0.7': {'strategy': 'smote', 'sampling_ratio': 0.7},\n",
    "    'undersample_0.5': {'strategy': 'undersample', 'sampling_ratio': 0.5},\n",
    "    'combine': {'strategy': 'combine', 'sampling_ratio': 0.3}\n",
    "}\n",
    "\n",
    "# Grille d'hyperparam√®tres pour la r√©gression logistique (OPTIMIS√âE)\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs'],\n",
    "    'classifier__max_iter': [100]\n",
    "}\n",
    "\n",
    "# Grille d'hyperparam√®tres pour LightGBM\n",
    "param_grid_lgb = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__num_leaves': [31, 50],\n",
    "    'classifier__max_depth': [-1, 10, 15]\n",
    "}\n",
    "\n",
    "# Scorer personnalis√© pour le F2-score\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834d7e4",
   "metadata": {},
   "source": [
    "#### Test de toutes les strat√©gies de r√©√©quilibrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04181a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction helper pour utiliser GridSearch ou RandomizedSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_search_cv(pipeline, param_grid, cv, scoring, config):\n",
    "    \"\"\"\n",
    "    Cr√©e GridSearchCV ou RandomizedSearchCV selon la configuration\n",
    "    \"\"\"\n",
    "    if config['use_randomized']:\n",
    "        return RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            n_iter=config['n_iter'],\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=config['verbose'],\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        return GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=config['verbose']\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Fonction create_search_cv initialis√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition de la fonction create_balanced_pipeline\n",
    "# IMPORTANT: Utilise imblearn.pipeline.Pipeline SEULEMENT avec r√©√©quilibrage\n",
    "def create_balanced_pipeline(classifier, strategy='none', sampling_ratio=None, scaler=None):\n",
    "    \"\"\"\n",
    "    Cr√©e un pipeline avec r√©√©quilibrage des donn√©es et classification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    classifier : estimator\n",
    "        Le classificateur √† utiliser (LogisticRegression, LGBMClassifier, etc.)\n",
    "    strategy : str\n",
    "        Strat√©gie de r√©√©quilibrage: 'none', 'smote', 'smote_auto', 'undersample', 'combine'\n",
    "    sampling_ratio : float\n",
    "        Ratio de sur√©chantillonnage pour SMOTE (0 √† 1)\n",
    "    scaler : transformer\n",
    "        Scaler pour normaliser les donn√©es (StandardScaler, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Pipeline sklearn ou imblearn selon la strat√©gie\n",
    "    \"\"\"\n",
    "    \n",
    "    steps = []\n",
    "    has_sampling = False  # Flag pour d√©terminer quel pipeline utiliser\n",
    "    \n",
    "    # Ajouter le scaler si fourni\n",
    "    if scaler is not None:\n",
    "        steps.append(('scaler', scaler))\n",
    "    \n",
    "    # Ajouter le r√©√©quilibrage selon la strat√©gie\n",
    "    if strategy == 'none':\n",
    "        # Pas de r√©√©quilibrage\n",
    "        pass\n",
    "    \n",
    "    elif strategy == 'smote':\n",
    "        # SMOTE avec ratio sp√©cifi√©\n",
    "        smote = SMOTE(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        steps.append(('smote', smote))\n",
    "        has_sampling = True\n",
    "    \n",
    "    elif strategy == 'smote_auto':\n",
    "        # SMOTE auto (√©quilibre complet 1:1)\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        steps.append(('smote', smote))\n",
    "        has_sampling = True\n",
    "    \n",
    "    elif strategy == 'undersample':\n",
    "        # Sous-√©chantillonnage al√©atoire\n",
    "        rus = RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        steps.append(('undersample', rus))\n",
    "        has_sampling = True\n",
    "    \n",
    "    elif strategy == 'combine':\n",
    "        # Combinaison: sous-√©chantillonnage + SMOTE\n",
    "        under = RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        over = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "        steps.append(('undersample', under))\n",
    "        steps.append(('smote', over))\n",
    "        has_sampling = True\n",
    "    \n",
    "    # Ajouter le classifier\n",
    "    steps.append(('classifier', classifier))\n",
    "    \n",
    "    # Retourner le pipeline appropri√©\n",
    "    if has_sampling:\n",
    "        # Utiliser imblearn.pipeline seulement si r√©√©quilibrage\n",
    "        return pipe(steps)\n",
    "    else:\n",
    "        # Pas de r√©√©quilibrage - utiliser sklearn.Pipeline standard\n",
    "        return Pipeline(steps)\n",
    "\n",
    "# Fonction sp√©cifique pour LightGBM - g√®re mieux le r√©√©quilibrage\n",
    "def create_lgbm_pipeline(classifier, strategy='smote', sampling_ratio=None):\n",
    "    \"\"\"\n",
    "    Cr√©e un pipeline pour LightGBM avec r√©√©quilibrage appropri√©\n",
    "    LightGBM n'a pas besoin de scaler (tree-based)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    classifier : LGBMClassifier\n",
    "        Le classificateur LightGBM\n",
    "    strategy : str\n",
    "        Strat√©gie de r√©√©quilibrage: 'class_weight', 'smote', 'undersample', 'combine'\n",
    "    sampling_ratio : float\n",
    "        Ratio de sur√©chantillonnage\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Pipeline imblearn ou sklearn selon la strat√©gie\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pour class_weight, utiliser sklearn.Pipeline simple\n",
    "    # (le class_weight est g√©r√© par le classifier lui-m√™me)\n",
    "    if strategy == 'class_weight':\n",
    "        return Pipeline([('classifier', classifier)])\n",
    "    \n",
    "    # Pour les autres strat√©gies, utiliser imblearn.pipeline avec r√©√©quilibrage\n",
    "    steps = []\n",
    "    \n",
    "    if strategy == 'smote':\n",
    "        smote = SMOTE(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        steps.append(('smote', smote))\n",
    "    \n",
    "    elif strategy == 'undersample':\n",
    "        rus = RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        steps.append(('undersample', rus))\n",
    "    \n",
    "    elif strategy == 'combine':\n",
    "        under = RandomUnderSampler(sampling_strategy=sampling_ratio, random_state=42)\n",
    "        over = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "        steps.append(('undersample', under))\n",
    "        steps.append(('smote', over))\n",
    "    \n",
    "    # Ajouter le classifier\n",
    "    steps.append(('classifier', classifier))\n",
    "    \n",
    "    # Retourner imblearn pipeline pour les strat√©gies avec r√©√©quilibrage\n",
    "    return pipe(steps)\n",
    "\n",
    "print(\"‚úÖ Fonction create_balanced_pipeline d√©finie (Pipeline sklearn pour 'none', imblearn pour autres strat√©gies)\")\n",
    "print(\"‚úÖ Fonction create_lgbm_pipeline d√©finie (Pipeline optimis√© pour LightGBM)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8024d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du dictionnaire pour stocker les r√©sultats\n",
    "results_lr = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation MLFlow\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.mlflow_tracking.tracker import MLFlowTracker\n",
    "\n",
    "# Initialiser le tracker MLFlow\n",
    "tracker = MLFlowTracker(experiment_name=\"credit-scoring-projet7\", tracking_uri=\"../mlruns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING ALL BALANCING STRATEGIES - LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Boucle sur toutes les strat√©gies\n",
    "for strategy_name, strategy_config in balancing_strategies.items():\n",
    "    print(f\"\\n{'‚îÄ'*70}\")\n",
    "    print(f\"üìä Testing: {strategy_name}\")\n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    \n",
    "    # D√©marrer une run MLFlow\n",
    "    run_name = f\"LogisticRegression_{strategy_name}\"\n",
    "    tracker.start_run(run_name=run_name)\n",
    "    \n",
    "    try:\n",
    "        # Cr√©er le mod√®le de base\n",
    "        if strategy_config['strategy'] == 'class_weight':\n",
    "            lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "            pipeline = create_balanced_pipeline(lr, 'none', scaler=StandardScaler())\n",
    "        else:\n",
    "            lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "            pipeline = create_balanced_pipeline(\n",
    "                lr, \n",
    "                strategy_config['strategy'], \n",
    "                sampling_ratio=strategy_config['sampling_ratio'],\n",
    "                scaler=StandardScaler()\n",
    "            )\n",
    "        \n",
    "        # Configurer la validation crois√©e stratifi√©e (optimis√©e)\n",
    "        cv = RepeatedStratifiedKFold(\n",
    "            n_splits=GRIDSEARCH_CONFIG['cv_splits'], \n",
    "            n_repeats=GRIDSEARCH_CONFIG['cv_repeats'], \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # GridSearchCV ou RandomizedSearchCV selon la configuration\n",
    "        grid_search = create_search_cv(\n",
    "            pipeline,\n",
    "            param_grid_lr,\n",
    "            cv=cv,\n",
    "            scoring=f2_scorer,\n",
    "            config=GRIDSEARCH_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Entra√Ænement\n",
    "        print(f\"\\n GridSearchCV...\")\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Meilleur mod√®le\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_cv_score = grid_search.best_score_\n",
    "        \n",
    "        # Pr√©dictions sur le test set\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "        \n",
    "        # Calcul des m√©triques\n",
    "        score_biz = score_metier(y_test, y_pred_test)\n",
    "        betascore = fbeta_score(y_test, y_pred_test, beta=2)\n",
    "        recall = recall_score(y_test, y_pred_test)\n",
    "        precision = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        auc = roc_auc_score(y_test, y_pred_test)\n",
    "        \n",
    "        # Affichage des r√©sultats\n",
    "        print(f\"\\n Results:\")\n",
    "        print(f\"‚îú‚îÄ Training time: {training_time:.2f}s\")\n",
    "        print(f\"‚îú‚îÄ Best CV F2-Score: {best_cv_score:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test F2-Score: {betascore:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Recall: {recall:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Precision: {precision:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test AUC: {auc:.4f}\")\n",
    "        print(f\"‚îî‚îÄ Score M√©tier: {score_biz}\")\n",
    "        \n",
    "        # Log des param√®tres et hyperparam√®tres dans MLFlow\n",
    "        params_to_log = {\n",
    "            'strategy': strategy_config['strategy'],\n",
    "            'sampling_ratio': strategy_config['sampling_ratio'] if strategy_config['sampling_ratio'] else 'N/A',\n",
    "            'scaler': 'StandardScaler',\n",
    "            'training_time': training_time,\n",
    "            **best_params\n",
    "        }\n",
    "        tracker.log_params(params_to_log)\n",
    "        \n",
    "        # Log des m√©triques dans MLFlow\n",
    "        metrics_to_log = {\n",
    "            'best_cv_f2_score': best_cv_score,\n",
    "            'test_f2_score': betascore,\n",
    "            'test_recall': recall,\n",
    "            'test_precision': precision,\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_auc': auc,\n",
    "            'score_metier': score_biz\n",
    "        }\n",
    "        tracker.log_metrics(metrics_to_log)\n",
    "        \n",
    "        # Log du mod√®le dans MLFlow\n",
    "        tracker.log_model(best_model, model_name=f\"lr_{strategy_name}\")\n",
    "        \n",
    "        # Stocker les r√©sultats\n",
    "        results_lr[strategy_name] = {\n",
    "            'model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'best_cv_score': best_cv_score,\n",
    "            'test_metrics': {\n",
    "                'f2_score': betascore,\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'score_metier': score_biz\n",
    "            },\n",
    "            'y_pred': y_pred_test,\n",
    "            'training_time': training_time,\n",
    "            'run_id': mlflow.active_run().info.run_id\n",
    "        }\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred_test, model_name=f\"LogisticRegression_{strategy_name}\")\n",
    "        \n",
    "        # Terminer la run\n",
    "        tracker.end_run()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec strat√©gie {strategy_name}: {str(e)}\")\n",
    "        tracker.end_run()\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ALL LOGISTIC REGRESSION RUNS COMPLETED\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837352b6",
   "metadata": {},
   "source": [
    "#### Comparaison des r√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b2b6b",
   "metadata": {},
   "source": [
    "### LightGBM <a class=\"anchor\" id=\"lightgbm\"></a>\n",
    "LightGBM est un gradient boosting bas√© sur des arbres de d√©cision optimis√© pour la vitesse et la performance (histogram-based, leaf-wise growth). \n",
    "\n",
    "Objectif: R√©aliser le m√™me processus que pour la r√©gression logistique avec:\n",
    "- Toutes les strat√©gies de r√©√©quilibrage (`none`, `class_weight`, `smote_*`, `smote_auto`, `undersample`, `combine`)\n",
    "- Optimisation des hyperparam√®tres principaux du mod√®le\n",
    "- Tracking MLflow complet (param√®tres, m√©triques, seuils, mod√®le)\n",
    "- S√©lection comparative finale.\n",
    "\n",
    "Sp√©cificit√©s LightGBM pour donn√©es d√©s√©quilibr√©es:\n",
    "- `class_weight` ou `is_unbalance=True` / `scale_pos_weight` (on utilisera `class_weight` pour coh√©rence)\n",
    "- Risque d'overfitting avec trop de feuilles ‚Üí contr√¥ler `num_leaves` et `max_depth`\n",
    "- R√©gularisation via `reg_alpha` / `reg_lambda`\n",
    "\n",
    "On optimise le F2-score (Recall prioritaire) et on suit aussi le score m√©tier (10*FN + FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIGHTGBM - CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Grille d'hyperparam√®tres pour LightGBM - ULTRA-SIMPLIFI√âE pour rapidit√©\n",
    "param_grid_lgbm = {\n",
    "    'classifier__num_leaves': [31],\n",
    "    'classifier__max_depth': [7],\n",
    "    'classifier__learning_rate': [0.05],\n",
    "    'classifier__n_estimators': [100],\n",
    "    'classifier__reg_alpha': [0.0],\n",
    "    'classifier__reg_lambda': [0.0]\n",
    "}\n",
    "\n",
    "# Dictionnaire pour stocker les r√©sultats\n",
    "results_lgbm = {}\n",
    "\n",
    "print(\"Configuration LightGBM termin√©e!\")\n",
    "print(f\"Nombre de strat√©gies √† tester: {len(balancing_strategies)}\")\n",
    "print(f\"Hyperparam√®tres √† optimiser: {list(param_grid_lgbm.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # RandomizedSearchCV pour optimisation (moins co√ªteux que GridSearchCV)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_grid_lgbm,\n",
    "            n_iter=GRIDSEARCH_CONFIG['n_iter'],  # Utiliser la config\n",
    "            cv=cv,\n",
    "            scoring=f2_scorer,\n",
    "            n_jobs=1,  # IMPORTANT: Utiliser n_jobs=1 pour √©viter les probl√®mes de pickling\n",
    "            verbose=GRIDSEARCH_CONFIG['verbose'],\n",
    "            random_state=42\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SCRIPT DE NETTOYAGE MLFLOW - √Ä EX√âCUTER EN PREMIER\n",
    "# ============================================================================\n",
    "\n",
    "import mlflow\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üßπ NETTOYAGE DES RUNS MLFLOW ACTIVES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Terminer toutes les runs actives\n",
    "run_ended = False\n",
    "max_attempts = 5\n",
    "\n",
    "for i in range(max_attempts):\n",
    "    try:\n",
    "        active_run = mlflow.active_run()\n",
    "        if active_run:\n",
    "            print(f\"‚ö†Ô∏è Run active d√©tect√©e: {active_run.info.run_id}\")\n",
    "            mlflow.end_run()\n",
    "            print(f\"‚úÖ Run {active_run.info.run_id} termin√©e\")\n",
    "            run_ended = True\n",
    "        else:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è Tentative {i+1}/{max_attempts}: {str(e)}\")\n",
    "        break\n",
    "\n",
    "if run_ended:\n",
    "    print(\"\\n‚úÖ Toutes les runs actives ont √©t√© termin√©es\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucune run active d√©tect√©e\")\n",
    "\n",
    "# V√©rification finale\n",
    "try:\n",
    "    active_run = mlflow.active_run()\n",
    "    if active_run:\n",
    "        print(f\"\\n‚ö†Ô∏è ATTENTION: Une run est encore active: {active_run.info.run_id}\")\n",
    "        print(\"Ex√©cutez: mlflow.end_run()\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Pr√™t pour d√©marrer l'entra√Ænement LightGBM\")\n",
    "except:\n",
    "    print(\"\\n‚úÖ Pr√™t pour d√©marrer l'entra√Ænement LightGBM\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3e7a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üßπ NETTOYAGE DES NOMS DE COLONNES\n",
      "======================================================================\n",
      "‚úÖ 6 colonnes renomm√©es pour compatibilit√© LightGBM\n",
      "‚úÖ 6 colonnes renomm√©es pour compatibilit√© LightGBM\n",
      "‚úÖ X_train_clean: (246004, 299)\n",
      "‚úÖ X_test_clean: (61501, 299)\n",
      "üìÅ Tracking directory: c:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\mlruns\n",
      "‚ö†Ô∏è Erreur:  Model registry functionality is unavailable; got unsupported URI 'c:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\n",
      "\n",
      "======================================================================\n",
      "TESTING ALL BALANCING STRATEGIES - LIGHTGBM\n",
      "======================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üìä Testing: none\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    },
    {
     "ename": "UnsupportedModelRegistryStoreURIException",
     "evalue": " Model registry functionality is unavailable; got unsupported URI 'c:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\registry.py:81\u001b[39m, in \u001b[36mStoreRegistry.get_store_builder\u001b[39m\u001b[34m(self, store_uri)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     store_builder = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'c'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnsupportedModelRegistryStoreURIException\u001b[39m Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\src\\mlflow_tracking\\tracker.py:54\u001b[39m, in \u001b[36mMLFlowTracker.start_run\u001b[39m\u001b[34m(self, run_name)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_run = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Si un run est d√©j√† actif, le fermer d'abord\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:390\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    384\u001b[39m         (\n\u001b[32m    385\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m         ).format(active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    389\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m client = \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\client.py:218\u001b[39m, in \u001b[36mMlflowClient.__init__\u001b[39m\u001b[34m(self, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m._registry_uri = registry_utils._resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28mself\u001b[39m._tracking_client = \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m._tracing_client = TracingClient(tracking_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:96\u001b[39m, in \u001b[36mTrackingServiceClient.__init__\u001b[39m\u001b[34m(self, tracking_uri)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:100\u001b[39m, in \u001b[36mTrackingServiceClient.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:216\u001b[39m, in \u001b[36m_get_store\u001b[39m\u001b[34m(store_uri, artifact_uri)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_store\u001b[39m(store_uri=\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:45\u001b[39m, in \u001b[36mTrackingStoreRegistry.get_store\u001b[39m\u001b[34m(self, store_uri, artifact_uri)\u001b[39m\n\u001b[32m     44\u001b[39m resolved_store_uri = utils._resolve_tracking_uri(store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:55\u001b[39m, in \u001b[36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[39m\u001b[34m(self, resolved_store_uri, artifact_uri)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     builder = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_store_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\registry.py:83\u001b[39m, in \u001b[36mStoreRegistry.get_store_builder\u001b[39m\u001b[34m(self, store_uri)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedModelRegistryStoreURIException(\n\u001b[32m     84\u001b[39m         unsupported_uri=store_uri, supported_uri_schemes=\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._registry.keys())\n\u001b[32m     85\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m store_builder\n",
      "\u001b[31mUnsupportedModelRegistryStoreURIException\u001b[39m:  Model registry functionality is unavailable; got unsupported URI 'c:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\registry.py:81\u001b[39m, in \u001b[36mStoreRegistry.get_store_builder\u001b[39m\u001b[34m(self, store_uri)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     store_builder = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'c'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnsupportedModelRegistryStoreURIException\u001b[39m Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m‚îÄ\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m run_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLightGBM_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mtracker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# Cr√©er le mod√®le LightGBM\u001b[39;00m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strategy_config[\u001b[33m'\u001b[39m\u001b[33mstrategy\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\src\\mlflow_tracking\\tracker.py:58\u001b[39m, in \u001b[36mMLFlowTracker.start_run\u001b[39m\u001b[34m(self, run_name)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Si un run est d√©j√† actif, le fermer d'abord\u001b[39;00m\n\u001b[32m     57\u001b[39m     mlflow.end_run()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_run = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_run\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:390\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    384\u001b[39m         (\n\u001b[32m    385\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m         ).format(active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    389\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m client = \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n\u001b[32m    392\u001b[39m     existing_run_id = run_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\client.py:218\u001b[39m, in \u001b[36mMlflowClient.__init__\u001b[39m\u001b[34m(self, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    216\u001b[39m final_tracking_uri = utils._resolve_tracking_uri(tracking_uri)\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m._registry_uri = registry_utils._resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28mself\u001b[39m._tracking_client = \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m._tracing_client = TracingClient(tracking_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:96\u001b[39m, in \u001b[36mTrackingServiceClient.__init__\u001b[39m\u001b[34m(self, tracking_uri)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.tracking_uri = tracking_uri\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:100\u001b[39m, in \u001b[36mTrackingServiceClient.store\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:216\u001b[39m, in \u001b[36m_get_store\u001b[39m\u001b[34m(store_uri, artifact_uri)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_store\u001b[39m(store_uri=\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:45\u001b[39m, in \u001b[36mTrackingStoreRegistry.get_store\u001b[39m\u001b[34m(self, store_uri, artifact_uri)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracking\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tracking_service\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m     44\u001b[39m resolved_store_uri = utils._resolve_tracking_uri(store_uri)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:55\u001b[39m, in \u001b[36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[39m\u001b[34m(self, resolved_store_uri, artifact_uri)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03mRetrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03mCaching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03mdepending on external configuration, such as environment variables\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     builder = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_store_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder(store_uri=resolved_store_uri, artifact_uri=artifact_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashash\\7\\projet7-scoring-credit\\venv_new\\Lib\\site-packages\\mlflow\\tracking\\registry.py:83\u001b[39m, in \u001b[36mStoreRegistry.get_store_builder\u001b[39m\u001b[34m(self, store_uri)\u001b[39m\n\u001b[32m     81\u001b[39m     store_builder = \u001b[38;5;28mself\u001b[39m._registry[scheme]\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedModelRegistryStoreURIException(\n\u001b[32m     84\u001b[39m         unsupported_uri=store_uri, supported_uri_schemes=\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._registry.keys())\n\u001b[32m     85\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m store_builder\n",
      "\u001b[31mUnsupportedModelRegistryStoreURIException\u001b[39m:  Model registry functionality is unavailable; got unsupported URI 'c:\\ashash\\7\\projet7-scoring-credit\\notebooks\\..\\mlruns' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SCRIPT COMPLET : LIGHTGBM AVEC NETTOYAGE DES COLONNES\n",
    "# ============================================================================\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import mlflow\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.mlflow_tracking.tracker import MLFlowTracker\n",
    "\n",
    "# ============================================================================\n",
    "# √âTAPE 1 : FONCTION DE NETTOYAGE DES NOMS DE COLONNES\n",
    "# ============================================================================\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Nettoie les noms de colonnes pour LightGBM\"\"\"\n",
    "    forbidden_chars = r'[\\[\\]{}:,\"\\']'\n",
    "    column_mapping = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_col = re.sub(forbidden_chars, '_', str(col))\n",
    "        new_col = re.sub(r'_+', '_', new_col)\n",
    "        new_col = new_col.strip('_')\n",
    "        column_mapping[col] = new_col\n",
    "    \n",
    "    df_clean = df.rename(columns=column_mapping)\n",
    "    \n",
    "    changes = [(old, new) for old, new in column_mapping.items() if old != new]\n",
    "    if changes:\n",
    "        print(f\"‚úÖ {len(changes)} colonnes renomm√©es pour compatibilit√© LightGBM\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# ============================================================================\n",
    "# √âTAPE 2 : NETTOYER LES DONN√âES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üßπ NETTOYAGE DES NOMS DE COLONNES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train_clean = clean_column_names(X_train)\n",
    "X_test_clean = clean_column_names(X_test)\n",
    "\n",
    "print(f\"‚úÖ X_train_clean: {X_train_clean.shape}\")\n",
    "print(f\"‚úÖ X_test_clean: {X_test_clean.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# √âTAPE 3 : ENTRA√éNEMENT LIGHTGBM\n",
    "# ============================================================================\n",
    "\n",
    "# Initialiser le tracker MLFlow\n",
    "tracker = MLFlowTracker(experiment_name=\"credit-scoring-projet7\", tracking_uri=\"../mlruns\")\n",
    "\n",
    "# Dictionnaire pour stocker les r√©sultats\n",
    "results_lgbm = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING ALL BALANCING STRATEGIES - LIGHTGBM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Boucle sur toutes les strat√©gies\n",
    "for strategy_name, strategy_config in balancing_strategies.items():\n",
    "    print(f\"\\n{'‚îÄ'*70}\")\n",
    "    print(f\"üìä Testing: {strategy_name}\")\n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    \n",
    "    run_name = f\"LightGBM_{strategy_name}\"\n",
    "    tracker.start_run(run_name=run_name)\n",
    "    \n",
    "    try:\n",
    "        # Cr√©er le mod√®le LightGBM\n",
    "        if strategy_config['strategy'] == 'class_weight':\n",
    "            lgbm = LGBMClassifier(\n",
    "                class_weight='balanced',\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            )\n",
    "            pipeline = create_lgbm_pipeline(lgbm, strategy='class_weight')\n",
    "        else:\n",
    "            lgbm = LGBMClassifier(\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbose=-1\n",
    "            )\n",
    "            pipeline = create_lgbm_pipeline(\n",
    "                lgbm, \n",
    "                strategy=strategy_config['strategy'], \n",
    "                sampling_ratio=strategy_config['sampling_ratio']\n",
    "            )\n",
    "        \n",
    "        # Validation crois√©e\n",
    "        cv = RepeatedStratifiedKFold(\n",
    "            n_splits=GRIDSEARCH_CONFIG['cv_splits'], \n",
    "            n_repeats=GRIDSEARCH_CONFIG['cv_repeats'], \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Recherche d'hyperparam√®tres\n",
    "        grid_search = create_search_cv(\n",
    "            pipeline,\n",
    "            param_grid_lgb,\n",
    "            cv=cv,\n",
    "            scoring=f2_scorer,\n",
    "            config=GRIDSEARCH_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Entra√Ænement\n",
    "        print(f\"\\nüîç {'RandomizedSearchCV' if GRIDSEARCH_CONFIG['use_randomized'] else 'GridSearchCV'}...\")\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train_clean, y_train)  # ‚Üê DONN√âES NETTOY√âES\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Meilleur mod√®le\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_cv_score = grid_search.best_score_\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        y_pred_test = best_model.predict(X_test_clean)  # ‚Üê DONN√âES NETTOY√âES\n",
    "        y_pred_proba_test = best_model.predict_proba(X_test_clean)[:, 1]\n",
    "        \n",
    "        # M√©triques\n",
    "        score_biz = score_metier(y_test, y_pred_test)\n",
    "        betascore = fbeta_score(y_test, y_pred_test, beta=2)\n",
    "        recall = recall_score(y_test, y_pred_test)\n",
    "        precision = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "        \n",
    "        # Affichage\n",
    "        print(f\"\\nüìà Results:\")\n",
    "        print(f\"‚îú‚îÄ Training time: {training_time:.2f}s\")\n",
    "        print(f\"‚îú‚îÄ Best CV F2-Score: {best_cv_score:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test F2-Score: {betascore:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Recall: {recall:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Precision: {precision:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"‚îú‚îÄ Test AUC: {auc:.4f}\")\n",
    "        print(f\"‚îî‚îÄ Score M√©tier: {score_biz}\")\n",
    "        \n",
    "        # MLflow logging\n",
    "        params_to_log = {\n",
    "            'model_type': 'LightGBM',\n",
    "            'strategy': strategy_config['strategy'],\n",
    "            'sampling_ratio': strategy_config['sampling_ratio'] if strategy_config['sampling_ratio'] else 'N/A',\n",
    "            'scaler': 'None',\n",
    "            'training_time': training_time,\n",
    "            'cv_splits': GRIDSEARCH_CONFIG['cv_splits'],\n",
    "            'cv_repeats': GRIDSEARCH_CONFIG['cv_repeats'],\n",
    "            **best_params\n",
    "        }\n",
    "        tracker.log_params(params_to_log)\n",
    "        \n",
    "        metrics_to_log = {\n",
    "            'best_cv_f2_score': best_cv_score,\n",
    "            'test_f2_score': betascore,\n",
    "            'test_recall': recall,\n",
    "            'test_precision': precision,\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_auc': auc,\n",
    "            'score_metier': score_biz\n",
    "        }\n",
    "        tracker.log_metrics(metrics_to_log)\n",
    "        \n",
    "        tracker.log_model(best_model, model_name=f\"lgbm_{strategy_name}\")\n",
    "        \n",
    "        # Stocker r√©sultats\n",
    "        results_lgbm[strategy_name] = {\n",
    "            'model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'best_cv_score': best_cv_score,\n",
    "            'test_metrics': {\n",
    "                'f2_score': betascore,\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'score_metier': score_biz\n",
    "            },\n",
    "            'y_pred': y_pred_test,\n",
    "            'y_pred_proba': y_pred_proba_test,\n",
    "            'training_time': training_time,\n",
    "            'run_id': mlflow.active_run().info.run_id\n",
    "        }\n",
    "        \n",
    "        # Confusion matrix\n",
    "        plot_confusion_matrix(y_test, y_pred_test, model_name=f\"LightGBM_{strategy_name}\")\n",
    "        \n",
    "        tracker.end_run()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        tracker.end_run()\n",
    "        continue\n",
    "\n",
    "# ============================================================================\n",
    "# √âTAPE 4 : R√âSUM√â DES R√âSULTATS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ALL LIGHTGBM RUNS COMPLETED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SUMMARY - LIGHTGBM RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if results_lgbm:\n",
    "    print(f\"\\n{'Strategy':<20} {'F2-Score':<12} {'Recall':<10} {'Precision':<12} {'AUC':<10} {'Score M√©tier':<15}\")\n",
    "    print(\"‚îÄ\" * 90)\n",
    "    \n",
    "    for strategy_name, result in results_lgbm.items():\n",
    "        metrics = result['test_metrics']\n",
    "        print(f\"{strategy_name:<20} {metrics['f2_score']:<12.4f} {metrics['recall']:<10.4f} \"\n",
    "              f\"{metrics['precision']:<12.4f} {metrics['auc']:<10.4f} {metrics['score_metier']:<15}\")\n",
    "    \n",
    "    best_strategy = max(results_lgbm.items(), key=lambda x: x[1]['test_metrics']['f2_score'])\n",
    "    print(\"\\n\" + \"‚îÄ\" * 90)\n",
    "    print(f\"üèÜ Best Strategy: {best_strategy[0]} (F2-Score: {best_strategy[1]['test_metrics']['f2_score']:.4f})\")\n",
    "    \n",
    "    # Statistiques additionnelles\n",
    "    print(\"\\nüìà Statistiques additionnelles:\")\n",
    "    print(f\"‚îú‚îÄ Nombre de strat√©gies test√©es: {len(results_lgbm)}\")\n",
    "    print(f\"‚îú‚îÄ Temps total d'entra√Ænement: {sum(r['training_time'] for r in results_lgbm.values()):.2f}s\")\n",
    "    print(f\"‚îî‚îÄ Temps moyen par strat√©gie: {sum(r['training_time'] for r in results_lgbm.values())/len(results_lgbm):.2f}s\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Aucun r√©sultat disponible\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8902469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fermer proprement toute run MLflow active\n",
    "import mlflow\n",
    "try:\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "        print(\"‚úÖ Run MLflow ferm√©e proprement\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50dee5",
   "metadata": {},
   "source": [
    "## S√©lection du meilleur mod√®le <a class=\"anchor\" id=\"best\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "if 'results_lr' in globals() and results_lr:\n",
    "    for strategy_name, result in results_lr.items():\n",
    "        metrics = result['test_metrics']\n",
    "        all_results.append({\n",
    "            'Model': 'Logistic Regression',\n",
    "            'Strategy': strategy_name,\n",
    "            'F2-Score': metrics['f2_score'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'Precision': metrics['precision'],\n",
    "            'Accuracy': metrics['accuracy'],\n",
    "            'AUC': metrics['auc'],\n",
    "            'Score M√©tier': metrics['score_metier'],\n",
    "            'CV F2-Score': result['best_cv_score'],\n",
    "            'Training Time (s)': result['training_time']\n",
    "        })\n",
    "\n",
    "# --- LightGBM ---\n",
    "if 'results_lgbm' in globals() and results_lgbm:\n",
    "    for strategy_name, result in results_lgbm.items():\n",
    "        metrics = result['test_metrics']\n",
    "        all_results.append({\n",
    "            'Model': 'LightGBM',\n",
    "            'Strategy': strategy_name,\n",
    "            'F2-Score': metrics['f2_score'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'Precision': metrics['precision'],\n",
    "            'Accuracy': metrics['accuracy'],\n",
    "            'AUC': metrics['auc'],\n",
    "            'Score M√©tier': metrics['score_metier'],\n",
    "            'CV F2-Score': result['best_cv_score'],\n",
    "            'Training Time (s)': result['training_time']\n",
    "        })\n",
    "\n",
    "df_models_recap = pd.DataFrame(all_results)\n",
    "\n",
    "if len(df_models_recap) == 0:\n",
    "    print(\"\\n Aucun r√©sultat trouv√©.\")\n",
    "else:\n",
    "    df_models_recap = df_models_recap.sort_values('F2-Score', ascending=False).reset_index(drop=True)\n",
    "    df_models_recap.insert(0, 'Rank', range(1, len(df_models_recap) + 1))\n",
    "\n",
    "    # =====================\n",
    "    #     STYLE DATAFRAME\n",
    "    # =====================\n",
    "\n",
    "    styled_df = (\n",
    "        df_models_recap.style\n",
    "        .background_gradient(subset=['Score M√©tier'], cmap='RdYlGn')\n",
    "        .background_gradient(subset=['F2-Score'], cmap='RdYlGn', vmin=0.4, vmax=0.8)\n",
    "        .background_gradient(subset=['Recall'], cmap='YlOrRd', vmin=0.4, vmax=1.0)\n",
    "        .background_gradient(subset=['Precision'], cmap='Blues', vmin=0.3, vmax=0.8)\n",
    "        .background_gradient(subset=['AUC'], cmap='Purples', vmin=0.5, vmax=0.9)\n",
    "        .highlight_max(subset=['F2-Score'], color='#90EE90')\n",
    "        .highlight_max(subset=['Recall'], color='#FFD700')\n",
    "        .highlight_max(subset=['AUC'], color='#87CEEB')\n",
    "        .highlight_min(subset=['Score M√©tier'], color=\"#90EE90\")\n",
    "        .set_properties(**{\n",
    "            'text-align': 'center',\n",
    "            'font-size': '12px',\n",
    "            'border': '1px solid #ddd',\n",
    "            'padding': '8px'\n",
    "        })\n",
    "        .set_table_styles([\n",
    "            {\n",
    "                'selector': 'th',\n",
    "                'props': [\n",
    "                    ('background-color', '#2E86AB'),\n",
    "                    ('color', 'white'),\n",
    "                    ('font-weight', 'bold'),\n",
    "                    ('text-align', 'center'),\n",
    "                    ('padding', '12px'),\n",
    "                    ('border', '1px solid white'),\n",
    "                    ('font-size', '13px')\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'selector': 'tr:hover',\n",
    "                'props': [\n",
    "                    ('background-color', \"#1fbb5b\"),\n",
    "                    ('cursor', 'pointer')\n",
    "                ]\n",
    "            }\n",
    "        ])\n",
    "        .format({\n",
    "            'F2-Score': '{:.4f}',\n",
    "            'Recall': '{:.4f}',\n",
    "            'Precision': '{:.4f}',\n",
    "            'Accuracy': '{:.4f}',\n",
    "            'AUC': '{:.4f}',\n",
    "            'CV F2-Score': '{:.4f}',\n",
    "            'Score M√©tier': '{:,.0f}',\n",
    "            'Training Time (s)': '{:.2f}'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    print(\"\\n\")\n",
    "    display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1154ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un barplot montrant la performance sur le fbeta_score et le score m√©tier\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä BARPLOT COMPARATIF: F2-SCORE vs SCORE M√âTIER\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(all_results) \n",
    "plot_df['Mod√®le'] = plot_df['Model'].str[:2].str.upper() + \"_\" + plot_df['Strategy'].str[:8]\n",
    "\n",
    "# Cr√©er le plot avec les donn√©es correctes\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Cr√©er une nouvelle figure avec positions x explicites pour √©viter le conflit\n",
    "x_pos = np.arange(len(plot_df))\n",
    "bars = ax1.bar(x_pos, plot_df['Score M√©tier'].values, color=plt.cm.viridis(np.linspace(0, 1, len(plot_df))), alpha=0.8)\n",
    "\n",
    "ax1.set_title(\"√âvaluation des mod√®les LR selon le Score M√©tier et le F2-Score\", \n",
    "              fontweight=\"bold\", fontsize=14, pad=20)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(plot_df['Mod√®le'].values, rotation=45, ha='right', fontsize=10)\n",
    "ax1.yaxis.label.set_color('tab:purple')\n",
    "ax1.tick_params(axis='y', colors='tab:purple')\n",
    "ax1.set_ylabel('Score M√©tier (plus bas = mieux)', fontsize=11, fontweight='bold', color='tab:purple')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Twin axis pour le F2-Score\n",
    "ax2 = ax1.twinx()\n",
    "line = ax2.plot(x_pos, plot_df['F2-Score'].values, marker='o', \n",
    "                color='tab:orange', linewidth=3, markersize=8, label='F2-Score')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.yaxis.label.set_color('tab:orange')\n",
    "ax2.tick_params(axis='y', colors='tab:orange')\n",
    "ax2.set_ylabel('F2-Score (plus haut = mieux)', fontsize=11, fontweight='bold', color='tab:orange')\n",
    "ax2.grid(None)\n",
    "\n",
    "# Ajouter les valeurs sur les points\n",
    "for i, val in enumerate(plot_df['F2-Score'].values):\n",
    "    ax2.text(i, val + 0.02, f'{val:.4f}', ha='center', fontsize=9, fontweight='bold', color='tab:orange')\n",
    "\n",
    "# L√©gende\n",
    "ax1.legend(['Score M√©tier'], loc='upper left', fontsize=10)\n",
    "ax2.legend(['F2-Score'], loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# üèÜ EXTRACTION DU MEILLEUR MOD√àLE (RANK 1) ET FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üèÜ MEILLEUR MOD√àLE - RANK 1\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# R√©cup√©rer la ligne du meilleur mod√®le\n",
    "best_model_row = df_models_recap.loc[0]\n",
    "\n",
    "print(f\"\\nüìä Meilleur Mod√®le:\")\n",
    "print(f\"  ‚îú‚îÄ Mod√®le: {best_model_row['Model']}\")\n",
    "print(f\"  ‚îú‚îÄ Strat√©gie: {best_model_row['Strategy']}\")\n",
    "print(f\"  ‚îú‚îÄ F2-Score: {best_model_row['F2-Score']:.4f}\")\n",
    "print(f\"  ‚îú‚îÄ Recall: {best_model_row['Recall']:.4f}\")\n",
    "print(f\"  ‚îú‚îÄ Precision: {best_model_row['Precision']:.4f}\")\n",
    "print(f\"  ‚îú‚îÄ Accuracy: {best_model_row['Accuracy']:.4f}\")\n",
    "print(f\"  ‚îú‚îÄ AUC: {best_model_row['AUC']:.4f}\")\n",
    "print(f\"  ‚îú‚îÄ Score M√©tier: {best_model_row['Score M√©tier']:.0f}\")\n",
    "print(f\"  ‚îî‚îÄ Training Time: {best_model_row['Training Time (s)']:.2f}s\")\n",
    "\n",
    "# D√©terminer le meilleur mod√®le √† partir des dictionnaires\n",
    "model_type = best_model_row['Model']\n",
    "strategy = best_model_row['Strategy']\n",
    "\n",
    "if model_type == 'Logistic Regression':\n",
    "    best_model_obj = results_lr[strategy]['model']\n",
    "    print(f\"\\n‚úÖ Mod√®le s√©lectionn√©: Logistic Regression - {strategy}\")\n",
    "else:\n",
    "    best_model_obj = results_lgbm[strategy]['model']\n",
    "    print(f\"\\n‚úÖ Mod√®le s√©lectionn√©: LightGBM - {strategy}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä FEATURE IMPORTANCE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# V√©rifier le type de mod√®le et extraire les coefficients/importance\n",
    "if hasattr(best_model_obj, 'named_steps'):\n",
    "    # C'est une pipeline\n",
    "    classifier = best_model_obj.named_steps.get('classifier')\n",
    "else:\n",
    "    classifier = best_model_obj\n",
    "\n",
    "# D√©terminer le type et extraire l'importance\n",
    "if model_type == 'Logistic Regression':\n",
    "    # Pour Logistic Regression, utiliser les coefficients\n",
    "    if hasattr(classifier, 'coef_'):\n",
    "        importance_values = np.abs(classifier.coef_[0])\n",
    "        importance_type = \"Coefficients Absolus (Logistic Regression)\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Impossible d'extraire les coefficients du mod√®le\")\n",
    "        importance_values = None\n",
    "        \n",
    "elif model_type == 'LightGBM':\n",
    "    # Pour LightGBM, utiliser feature_importances_\n",
    "    if hasattr(classifier, 'feature_importances_'):\n",
    "        importance_values = classifier.feature_importances_\n",
    "        importance_type = \"Feature Importances (LightGBM)\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Impossible d'extraire les feature importances du mod√®le\")\n",
    "        importance_values = None\n",
    "\n",
    "# Cr√©er le dataframe d'importance\n",
    "if importance_values is not None:\n",
    "    # R√©cup√©rer les noms des features\n",
    "    if model_type == 'LightGBM':\n",
    "        feature_names = X_test_clean.columns.tolist()\n",
    "    else:\n",
    "        feature_names = X_test.columns.tolist()\n",
    "    \n",
    "    # Cr√©er un dataframe avec importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance_values\n",
    "    }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Afficher les top 20 features\n",
    "    print(f\"\\nüîù TOP 20 FEATURES - {importance_type}:\")\n",
    "    print(\"\\n\")\n",
    "    top_20 = importance_df.head(20)\n",
    "    print(top_20.to_string(index=False))\n",
    "    \n",
    "    # =====================\n",
    "    # PLOT TOP 20 FEATURES\n",
    "    # =====================\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Cr√©er le barplot\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(top_20)))\n",
    "    bars = plt.barh(range(len(top_20)), top_20['Importance'].values, color=colors)\n",
    "    \n",
    "    # Personnaliser le plot\n",
    "    plt.yticks(range(len(top_20)), top_20['Feature'].values, fontsize=10)\n",
    "    plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'üèÜ Top 20 Features - {model_type} ({strategy})\\n{importance_type}', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for i, (idx, row) in enumerate(top_20.iterrows()):\n",
    "        plt.text(row['Importance'], i, f\" {row['Importance']:.4f}\", \n",
    "                va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    plt.show()\n",
    "    \n",
    "    # =====================\n",
    "    # PLOT TOP 10 FEATURES (PIE CHART)\n",
    "    # =====================\n",
    "    \n",
    "    top_10 = importance_df.head(10)\n",
    "    other_importance = importance_df.iloc[10:]['Importance'].sum()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Cr√©er les donn√©es pour le pie chart\n",
    "    pie_labels = list(top_10['Feature'].values) + ['Others']\n",
    "    pie_values = list(top_10['Importance'].values) + [other_importance]\n",
    "    colors_pie = plt.cm.Set3(np.linspace(0, 1, len(pie_labels)))\n",
    "    \n",
    "    # Cr√©er le pie chart\n",
    "    wedges, texts, autotexts = plt.pie(pie_values, \n",
    "                                        labels=pie_labels,\n",
    "                                        autopct='%1.1f%%',\n",
    "                                        startangle=90,\n",
    "                                        colors=colors_pie,\n",
    "                                        textprops={'fontsize': 10})\n",
    "    \n",
    "    # Mettre en gras les pourcentages\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(9)\n",
    "    \n",
    "    plt.title(f'üèÜ Top 10 Features Distribution - {model_type} ({strategy})', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =====================\n",
    "    # STATISTIQUES\n",
    "    # =====================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"üìà STATISTIQUES D'IMPORTANCE\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(f\"\\n{'Total Features':<30} {len(importance_df)}\")\n",
    "    print(f\"{'Importance Max':<30} {importance_df['Importance'].max():.4f}\")\n",
    "    print(f\"{'Importance Min':<30} {importance_df['Importance'].min():.4f}\")\n",
    "    print(f\"{'Importance Mean':<30} {importance_df['Importance'].mean():.4f}\")\n",
    "    print(f\"{'Importance Std':<30} {importance_df['Importance'].std():.4f}\")\n",
    "    \n",
    "    # % cumulative importance\n",
    "    importance_df['Cumulative_Importance'] = importance_df['Importance'].cumsum() / importance_df['Importance'].sum()\n",
    "    \n",
    "    print(f\"\\n{'Cumulative Importance:':<30}\")\n",
    "    print(f\"  ‚îú‚îÄ Top 5 features: {importance_df['Cumulative_Importance'].iloc[4]:.2%}\")\n",
    "    print(f\"  ‚îú‚îÄ Top 10 features: {importance_df['Cumulative_Importance'].iloc[9]:.2%}\")\n",
    "    print(f\"  ‚îú‚îÄ Top 20 features: {importance_df['Cumulative_Importance'].iloc[19]:.2%}\")\n",
    "    print(f\"  ‚îî‚îÄ All features: {importance_df['Cumulative_Importance'].iloc[-1]:.2%}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0448a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "affiche les hypermaremetres de meilleur modele "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìä AFFICHAGE DES R√âSULTATS ET HYPERPARAM√àTRES - LIGHTGBM CLASS_WEIGHT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä R√âSULTATS D√âTAILL√âS - LightGBM CLASS_WEIGHT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'results_lgbm' in globals() and 'class_weight' in results_lgbm:\n",
    "    result = results_lgbm['class_weight']\n",
    "    metrics = result['test_metrics']\n",
    "    best_params = result['best_params']\n",
    "    \n",
    "    print(f\"\\nüìà M√âTRIQUES DE TEST:\")\n",
    "    print(f\"  ‚îú‚îÄ F2-Score: {metrics['f2_score']:.4f}\")\n",
    "    print(f\"  ‚îú‚îÄ Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"  ‚îú‚îÄ Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  ‚îú‚îÄ Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  ‚îú‚îÄ AUC: {metrics['auc']:.4f}\")\n",
    "    print(f\"  ‚îî‚îÄ Score M√©tier: {metrics['score_metier']:.0f}\")\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è HYPERPARAM√àTRES:\")\n",
    "    for param_name, param_value in best_params.items():\n",
    "        print(f\"  ‚îú‚îÄ {param_name}: {param_value}\")\n",
    "    \n",
    "    print(f\"\\nüìä VALIDATION CROIS√âE:\")\n",
    "    print(f\"  ‚îî‚îÄ Best CV F2-Score: {result['best_cv_score']:.4f}\")\n",
    "    \n",
    "    # Plot comparatif\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Metrics comparison\n",
    "    metrics_names = ['F2-Score', 'Recall', 'Precision', 'Accuracy', 'AUC']\n",
    "    metrics_values = [metrics['f2_score'], metrics['recall'], metrics['precision'], \n",
    "                      metrics['accuracy'], metrics['auc']]\n",
    "    colors_metrics = plt.cm.viridis(np.linspace(0, 1, len(metrics_names)))\n",
    "    \n",
    "    bars1 = ax1.bar(metrics_names, metrics_values, color=colors_metrics, alpha=0.8)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('LightGBM Class_Weight - M√©triques de Test', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, val in zip(bars1, metrics_values):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Plot 2: Business metrics\n",
    "    ax2.text(0.5, 0.8, 'R√âSULTATS M√âTIER', ha='center', fontsize=14, fontweight='bold',\n",
    "            transform=ax2.transAxes)\n",
    "    ax2.text(0.5, 0.6, f\"Score M√©tier: {metrics['score_metier']:.0f}\", ha='center', fontsize=13,\n",
    "            transform=ax2.transAxes, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    ax2.text(0.5, 0.4, f\"CV F2-Score: {result['best_cv_score']:.4f}\", ha='center', fontsize=13,\n",
    "            transform=ax2.transAxes, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    ax2.text(0.5, 0.2, f\"Temps d'entra√Ænement: {result['training_time']:.2f}s\", ha='center', \n",
    "            fontsize=13, transform=ax2.transAxes, bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ R√©sultats affich√©s avec succ√®s!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è R√©sultats LightGBM class_weight non trouv√©s. Assurez-vous d'avoir ex√©cut√© l'entra√Ænement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajoute un threshold pour optimiser le score m√©tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf872af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üéØ OPTIMISATION DU THRESHOLD POUR LE SCORE M√âTIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéØ OPTIMISATION DU THRESHOLD POUR LE SCORE M√âTIER\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'results_lgbm' in globals() and 'class_weight' in results_lgbm:\n",
    "    result = results_lgbm['class_weight']\n",
    "    best_model = result['model']\n",
    "    y_pred_proba = result['y_pred_proba']\n",
    "    \n",
    "    # Calculer le score m√©tier pour diff√©rents seuils\n",
    "    thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "    business_scores = []\n",
    "    f2_scores = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "        biz_score = score_metier(y_test, y_pred_threshold)\n",
    "        f2 = fbeta_score(y_test, y_pred_threshold, beta=2, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_threshold, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred_threshold, zero_division=0)\n",
    "        \n",
    "        business_scores.append(biz_score)\n",
    "        f2_scores.append(f2)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    # Trouver le seuil optimal pour le score m√©tier\n",
    "    optimal_idx_business = np.argmin(business_scores)\n",
    "    optimal_threshold_business = thresholds[optimal_idx_business]\n",
    "    optimal_business_score = business_scores[optimal_idx_business]\n",
    "    \n",
    "    # Trouver le seuil optimal pour le F2-score\n",
    "    optimal_idx_f2 = np.argmax(f2_scores)\n",
    "    optimal_threshold_f2 = thresholds[optimal_idx_f2]\n",
    "    optimal_f2_score = f2_scores[optimal_idx_f2]\n",
    "    \n",
    "    print(f\"\\nüéØ SEUILS OPTIMAUX:\")\n",
    "    print(f\"  ‚îú‚îÄ Seuil optimal pour Score M√©tier: {optimal_threshold_business:.2f}\")\n",
    "    print(f\"  ‚îÇ  ‚îî‚îÄ Score M√©tier √† ce seuil: {optimal_business_score:.0f}\")\n",
    "    print(f\"  ‚îú‚îÄ Seuil optimal pour F2-Score: {optimal_threshold_f2:.2f}\")\n",
    "    print(f\"  ‚îÇ  ‚îî‚îÄ F2-Score √† ce seuil: {optimal_f2_score:.4f}\")\n",
    "    print(f\"  ‚îî‚îÄ Seuil par d√©faut (0.50): {business_scores[50]:.0f}\")\n",
    "    \n",
    "    # Cr√©er un tableau comparatif\n",
    "    threshold_analysis = pd.DataFrame({\n",
    "        'Threshold': thresholds,\n",
    "        'Score M√©tier': business_scores,\n",
    "        'F2-Score': f2_scores,\n",
    "        'Recall': recalls,\n",
    "        'Precision': precisions\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìä TOP 10 MEILLEURS SEUILS (par Score M√©tier):\")\n",
    "    top_10_business = threshold_analysis.nsmallest(10, 'Score M√©tier')\n",
    "    print(top_10_business.to_string(index=False))\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Score M√©tier vs Threshold\n",
    "    ax1.plot(thresholds, business_scores, linewidth=2.5, color='red', label='Score M√©tier')\n",
    "    ax1.axvline(optimal_threshold_business, color='darkred', linestyle='--', linewidth=2, \n",
    "                label=f'Optimal ({optimal_threshold_business:.2f})')\n",
    "    ax1.axvline(0.5, color='gray', linestyle=':', linewidth=2, label='D√©faut (0.50)')\n",
    "    ax1.scatter([optimal_threshold_business], [optimal_business_score], \n",
    "               color='darkred', s=200, zorder=5, marker='*', edgecolors='black', linewidth=2)\n",
    "    ax1.set_xlabel('Threshold', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Score M√©tier (plus bas = mieux)', fontsize=11, fontweight='bold', color='red')\n",
    "    ax1.set_title('Score M√©tier en fonction du Threshold', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(fontsize=10, loc='upper right')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    # Plot 2: F2-Score, Recall, Precision vs Threshold\n",
    "    ax2.plot(thresholds, f2_scores, linewidth=2.5, color='green', label='F2-Score')\n",
    "    ax2.plot(thresholds, recalls, linewidth=2.5, color='blue', label='Recall')\n",
    "    ax2.plot(thresholds, precisions, linewidth=2.5, color='orange', label='Precision')\n",
    "    ax2.axvline(optimal_threshold_f2, color='darkgreen', linestyle='--', linewidth=2,\n",
    "                label=f'Optimal F2 ({optimal_threshold_f2:.2f})')\n",
    "    ax2.axvline(optimal_threshold_business, color='darkred', linestyle='--', linewidth=2,\n",
    "                label=f'Optimal M√©tier ({optimal_threshold_business:.2f})')\n",
    "    ax2.set_xlabel('Threshold', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('F2-Score, Recall et Precision en fonction du Threshold', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(fontsize=10, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Appliquer le seuil optimal\n",
    "    y_pred_optimized = (y_pred_proba >= optimal_threshold_business).astype(int)\n",
    "    \n",
    "    print(f\"\\nüìà COMPARAISON AVEC/SANS OPTIMISATION (Seuil = {optimal_threshold_business:.2f}):\")\n",
    "    print(f\"  ‚îú‚îÄ Score M√©tier (d√©faut 0.50): {business_scores[50]:.0f}\")\n",
    "    print(f\"  ‚îú‚îÄ Score M√©tier (optimis√© {optimal_threshold_business:.2f}): {optimal_business_score:.0f}\")\n",
    "    print(f\"  ‚îú‚îÄ Gain: {business_scores[50] - optimal_business_score:.0f} points\")\n",
    "    print(f\"  ‚îî‚îÄ Am√©lioration: {((business_scores[50] - optimal_business_score) / business_scores[50] * 100):.1f}%\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üîç LIME - LOCAL INTERPRETABLE MODEL-AGNOSTIC EXPLANATIONS (COMPATIBLE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üîç LIME - EXPLICATION LOCALE DES PR√âDICTIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'results_lgbm' in globals() and 'class_weight' in results_lgbm:\n",
    "    result = results_lgbm['class_weight']\n",
    "    best_model = result['model']\n",
    "    \n",
    "    # Pr√©parer les donn√©es pour LIME\n",
    "    if hasattr(best_model, 'named_steps'):\n",
    "        # Pipeline - utiliser les donn√©es nettoy√©es\n",
    "        X_explain = X_test_clean.values\n",
    "        feature_names = X_test_clean.columns.tolist()\n",
    "    else:\n",
    "        X_explain = X_test.values\n",
    "        feature_names = X_test.columns.tolist()\n",
    "    \n",
    "    # Initialiser l'explainer LIME\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=X_explain,\n",
    "        feature_names=feature_names,\n",
    "        class_names=['Non D√©faillant (0)', 'D√©faillant (1)'],\n",
    "        mode='classification',\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ LIME Explainer initialis√© avec {len(feature_names)} features\")\n",
    "    \n",
    "    # S√©lectionner quelques instances pour expliquer\n",
    "    y_pred_proba_best = best_model.predict_proba(X_explain)[:, 1]\n",
    "    y_pred_best = (y_pred_proba_best >= 0.5).astype(int)\n",
    "    \n",
    "    # Trouver des indices pour chaque cas\n",
    "    fn_indices = np.where((y_pred_best == 0) & (y_test.values == 1))[0]\n",
    "    fp_indices = np.where((y_pred_best == 1) & (y_test.values == 0))[0]\n",
    "    \n",
    "    \n",
    "    cases = {\n",
    "        'Faux N√©gatif (Erreur Co√ªteuse)': fn_indices[0] if len(fn_indices) > 0 else None,\n",
    "        'Faux Positif': fp_indices[0] if len(fp_indices) > 0 else None,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Cr√©er les explications pour chaque cas\n",
    "    for case_name, idx in cases.items():\n",
    "        if idx is not None:\n",
    "            print(f\"\\n{'‚îÄ'*100}\")\n",
    "            print(f\"üìç CAS: {case_name}\")\n",
    "            print(f\"{'‚îÄ'*100}\")\n",
    "            \n",
    "            try:\n",
    "                # G√©n√©rer l'explication LIME\n",
    "                exp = explainer.explain_instance(\n",
    "                    data_row=X_explain[idx],\n",
    "                    predict_fn=best_model.predict_proba,\n",
    "                    num_features=10,\n",
    "                    top_labels=2\n",
    "                )\n",
    "                \n",
    "                # Afficher les informations\n",
    "                print(f\"\\nüìä Pr√©diction: Classe {y_pred_best[idx]} (probabilit√©: {y_pred_proba_best[idx]:.4f})\")\n",
    "                print(f\"üìä R√©alit√©: Classe {y_test.values[idx]}\")\n",
    "                \n",
    "                print(f\"\\nüéØ TOP 10 FEATURES INFLUENTES:\")\n",
    "                # R√©cup√©rer les features importantes pour cette pr√©diction\n",
    "                exp_list = exp.as_list(label=1)  # Label 1 = D√©faillant\n",
    "                for i, (feature, weight) in enumerate(exp_list, 1):\n",
    "                    arrow = \"‚ûï\" if weight > 0 else \"‚ûñ\"\n",
    "                    print(f\"  {i:2d}. {arrow} {feature:<75s} (poids: {weight:+.4f})\")\n",
    "                \n",
    "                # Cr√©er un plot pour LIME\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                \n",
    "                # Extraire features et weights\n",
    "                features_lime = [x[0].split('<=')[0].split('>')[0].strip() if '<=' in x[0] or '>' in x[0] else x[0] for x in exp_list]\n",
    "                weights_lime = [x[1] for x in exp_list]\n",
    "                colors_lime = ['green' if w > 0 else 'red' for w in weights_lime]\n",
    "                \n",
    "                # Cr√©er le barplot\n",
    "                y_pos = np.arange(len(features_lime))\n",
    "                ax.barh(y_pos, weights_lime, color=colors_lime, alpha=0.7, edgecolor='black')\n",
    "                ax.set_yticks(y_pos)\n",
    "                ax.set_yticklabels(features_lime, fontsize=10)\n",
    "                ax.set_xlabel('Feature Weight (Impact sur la pr√©diction)', fontsize=11, fontweight='bold')\n",
    "                ax.set_title(f'LIME Explanation - {case_name}\\n(Pr√©diction: {y_pred_best[idx]}, R√©alit√©: {y_test.values[idx]})', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "                ax.axvline(x=0, color='black', linewidth=2)\n",
    "                ax.grid(axis='x', alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(f\"\\n‚úÖ Explication LIME g√©n√©r√©e pour {case_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erreur lors de la g√©n√©ration LIME: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"üìå R√âSUM√â LIME:\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"‚îú‚îÄ Total d'instances analysables: {len(X_explain)}\")\n",
    "    print(f\"‚îú‚îÄ Faux N√©gatifs trouv√©s: {len(fn_indices)} (erreurs co√ªteuses)\")\n",
    "    print(f\"‚îú‚îÄ Faux Positifs trouv√©s: {len(fp_indices)}(erreurs √† r√©duire)\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\n‚úÖ LIME analysis compl√©t√©e!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è R√©sultats LightGBM class_weight non trouv√©s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341caac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396148ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìä SHAP - SHAPLEY ADDITIVE EXPLANATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä SHAP - SHAPLEY ADDITIVE EXPLANATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'results_lgbm' in globals() and 'class_weight' in results_lgbm:\n",
    "    result = results_lgbm['class_weight']\n",
    "    best_model = result['model']\n",
    "    \n",
    "    # Pr√©parer les donn√©es pour SHAP\n",
    "    if hasattr(best_model, 'named_steps'):\n",
    "        # Pipeline - utiliser les donn√©es nettoy√©es\n",
    "        X_explain = X_test_clean.iloc[:200]  # Limiter pour performance\n",
    "        feature_names = X_test_clean.columns.tolist()\n",
    "        classifier = best_model.named_steps.get('classifier')\n",
    "    else:\n",
    "        X_explain = X_test.iloc[:200]\n",
    "        feature_names = X_test.columns.tolist()\n",
    "        classifier = best_model\n",
    "    \n",
    "    print(f\"\\n‚úÖ Pr√©paration des donn√©es SHAP:\")\n",
    "    print(f\"  ‚îú‚îÄ Nombre d'instances: {len(X_explain)}\")\n",
    "    print(f\"  ‚îú‚îÄ Nombre de features: {len(feature_names)}\")\n",
    "    print(f\"  ‚îî‚îÄ Type de mod√®le: {type(classifier).__name__}\")\n",
    "    \n",
    "    try:\n",
    "        # Cr√©er l'explainer SHAP\n",
    "        print(f\"\\nüîÑ Initialisation de l'explainer SHAP (TreeExplainer)...\")\n",
    "        explainer = shap.TreeExplainer(classifier)\n",
    "        \n",
    "        # Calculer les SHAP values\n",
    "        print(f\"‚è≥ Calcul des SHAP values (cela peut prendre quelques secondes)...\")\n",
    "        shap_values = explainer.shap_values(X_explain)\n",
    "        \n",
    "        print(f\"‚úÖ SHAP values calcul√©es!\")\n",
    "        \n",
    "        # Afficher les statistiques\n",
    "        if isinstance(shap_values, list):\n",
    "            print(f\"\\nüìä SHAP VALUES - Classe 1 (D√©faillant):\")\n",
    "            shap_vals = shap_values[1]\n",
    "        else:\n",
    "            shap_vals = shap_values\n",
    "            print(f\"\\nüìä SHAP VALUES:\")\n",
    "        \n",
    "        # 1. SUMMARY PLOT (Bar)\n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"üìà PLOT 1: MEAN ABSOLUTE SHAP VALUES (Feature Importance)\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_vals, X_explain, feature_names=feature_names, \n",
    "                         plot_type=\"bar\", show=False)\n",
    "        plt.title(\"SHAP Summary Plot - Feature Importance (Mean |SHAP|)\", fontsize=12, fontweight='bold')\n",
    "        plt.xlabel(\"Mean |SHAP value|\", fontsize=11, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"‚úÖ Summary plot g√©n√©r√©!\")\n",
    "        \n",
    "        # 2. SUMMARY PLOT (Beeswarm)\n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"üìä PLOT 2: SHAP BEESWARM (Feature Values vs SHAP Impact)\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_vals, X_explain, feature_names=feature_names, \n",
    "                         plot_type=\"violin\", show=False)\n",
    "        plt.title(\"SHAP Beeswarm Plot - Impact des Features\", fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"‚úÖ Beeswarm plot g√©n√©r√©!\")\n",
    "        \n",
    "        # 3. FORCE PLOT pour quelques instances\n",
    "        print(f\"\\n{'‚îÄ'*100}\")\n",
    "        print(f\"‚ö° PLOT 3: FORCE PLOTS (Explications par instance)\")\n",
    "        print(f\"{'‚îÄ'*100}\")\n",
    "        \n",
    "        # S√©lectionner 3 instances int√©ressantes\n",
    "        y_pred_proba = best_model.predict_proba(X_explain)[:, 1]\n",
    "        \n",
    "        # Instance avec haute probabilit√© de d√©faut\n",
    "        high_risk_idx = np.argmax(y_pred_proba)\n",
    "        # Instance avec basse probabilit√© de d√©faut\n",
    "        low_risk_idx = np.argmin(y_pred_proba)\n",
    "        # Instance avec probabilit√© moyenne\n",
    "        medium_risk_idx = np.argmin(np.abs(y_pred_proba - 0.5))\n",
    "        \n",
    "        instances = {\n",
    "            'Haut Risque (Prob=%.2f)' % y_pred_proba[high_risk_idx]: high_risk_idx,\n",
    "            'Risque Moyen (Prob=%.2f)' % y_pred_proba[medium_risk_idx]: medium_risk_idx,\n",
    "            'Bas Risque (Prob=%.2f)' % y_pred_proba[low_risk_idx]: low_risk_idx,\n",
    "        }\n",
    "        \n",
    "        for instance_name, idx in instances.items():\n",
    "            print(f\"\\n‚ú® Instance: {instance_name}\")\n",
    "            \n",
    "            # Cr√©er le force plot\n",
    "            fig, ax = plt.subplots(figsize=(14, 4))\n",
    "            \n",
    "            # Extraire top features pour cette instance\n",
    "            instance_shap = shap_vals[idx]\n",
    "            top_features_idx = np.argsort(np.abs(instance_shap))[-10:]\n",
    "            \n",
    "            # Cr√©er un plot horizontal\n",
    "            top_features = [feature_names[i] for i in top_features_idx]\n",
    "            top_shap_values = instance_shap[top_features_idx]\n",
    "            top_feature_values = X_explain.iloc[idx][top_features_idx].values\n",
    "            \n",
    "            colors = ['green' if v > 0 else 'red' for v in top_shap_values]\n",
    "            \n",
    "            y_pos = np.arange(len(top_features))\n",
    "            ax.barh(y_pos, top_shap_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels([f\"{feat}\\n(val: {val:.2f})\" \n",
    "                                for feat, val in zip(top_features, top_feature_values)], fontsize=9)\n",
    "            ax.set_xlabel('SHAP Value', fontsize=11, fontweight='bold')\n",
    "            ax.set_title(f'Top 10 SHAP Values - {instance_name}', fontsize=12, fontweight='bold')\n",
    "            ax.axvline(x=0, color='black', linewidth=2)\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # 4. STATISTIQUES\n",
    "        print(f\"\\n\" + \"=\"*100)\n",
    "        print(\"üìà STATISTIQUES SHAP:\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Top 10 features par moyenne SHAP\n",
    "        mean_shap = np.abs(shap_vals).mean(axis=0)\n",
    "        top_10_idx = np.argsort(mean_shap)[-10:][::-1]\n",
    "        \n",
    "        print(f\"\\nüîù TOP 10 FEATURES (Mean |SHAP|):\")\n",
    "        for rank, idx in enumerate(top_10_idx, 1):\n",
    "            print(f\"  {rank:2d}. {feature_names[idx]:<50s} (Mean |SHAP|: {mean_shap[idx]:.4f})\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ SHAP analysis compl√©t√©e!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors de l'analyse SHAP: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è R√©sultats LightGBM class_weight non trouv√©s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab0a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üèÜ EXTRACTION DES 30 FEATURES IMPORTANCES R√âELLES DU MOD√àLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üèÜ EXTRACTION DES 30 FEATURES IMPORTANCES R√âELLES DU MOD√àLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 1Ô∏è‚É£ V√©rifier si le mod√®le LightGBM existe\n",
    "print(\"\\n1Ô∏è‚É£  Recherche du mod√®le LightGBM entra√Æn√©...\")\n",
    "\n",
    "# Essayer de trouver le mod√®le LightGBM dans les variables locales\n",
    "lgb_model = None\n",
    "if 'clf' in locals():\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        lgb_model = clf\n",
    "        print(f\"   ‚úÖ Mod√®le LightGBM trouv√©: clf\")\n",
    "    elif hasattr(clf, 'named_steps'):\n",
    "        if 'classifier' in clf.named_steps and hasattr(clf.named_steps['classifier'], 'feature_importances_'):\n",
    "            lgb_model = clf.named_steps['classifier']\n",
    "            print(f\"   ‚úÖ Mod√®le LightGBM trouv√© dans Pipeline: clf.named_steps['classifier']\")\n",
    "\n",
    "if lgb_model is None:\n",
    "    print(f\"   ‚ö†Ô∏è  Mod√®le LightGBM non trouv√©. Utilisation des features pr√©d√©finies.\")\n",
    "    # Fallback vers les features pr√©d√©finies (v√©rifi√©es manuellement)\n",
    "    top_30_features = [\n",
    "        'CREDIT_DURATION', 'EXT_SOURCE_2', 'INSTAL_DAYS_PAST_DUE_MEAN',\n",
    "        'PAYMENT_RATE', 'POS_CNT_INSTLEMENT_FUTURE_MEAN', 'CREDIT_GOODS_PERC',\n",
    "        'AGE', 'POS_NB_CREDIT', 'BURO_CREDIT_ACTIVE_Active_SUM', 'BURO_AMT_CREDIT_SUM_DEBT_MEAN',\n",
    "        'YEARS_EMPLOYED', 'YEARS_ID_PUBLISH', 'INSTAL_PAYMENT_DIFF_MEAN', 'BURO_AMT_CREDIT_SUM_MEAN',\n",
    "        'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'BURO_YEARS_CREDIT_ENDDATE_MEAN', 'AMT_CREDIT',\n",
    "        'YEARS_LAST_PHONE_CHANGE', 'POS_MONTHS_BALANCE_MEAN', 'INSTAL_DAYS_BEFORE_DUE_MEAN',\n",
    "        'BURO_AMT_CREDIT_SUM_DEBT_SUM', 'CODE_GENDER', 'PREV_YEARS_DECISION_MEAN',\n",
    "        'REGION_POPULATION_RELATIVE', 'DEBT_RATIO', 'BURO_AMT_CREDIT_SUM_SUM',\n",
    "        'BURO_YEARS_CREDIT_ENDDATE_MAX', 'PREV_PAYMENT_RATE_MEAN', 'FEATURE_30'\n",
    "    ]\n",
    "else:\n",
    "    # 2Ô∏è‚É£ Extraire les feature importances du mod√®le LightGBM r√©el\n",
    "    print(\"\\n2Ô∏è‚É£  Extraction des feature importances du mod√®le LightGBM...\")\n",
    "    \n",
    "    importances = lgb_model.feature_importances_\n",
    "    feature_names = X_train_clean.columns.tolist()\n",
    "    \n",
    "    # Cr√©er un DataFrame des importances\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # S√©lectionner les 30 top features\n",
    "    top_30_features = importance_df.head(30)['feature'].tolist()\n",
    "    \n",
    "    print(f\"\\n   üéØ TOP 30 FEATURES IMPORTANCES (du mod√®le r√©el):\")\n",
    "    print(f\"   {'-'*80}\")\n",
    "    for i, (idx, row) in enumerate(importance_df.head(30).iterrows(), 1):\n",
    "        print(f\"   {i:2d}. {row['feature']:40s} ‚îÇ importance: {row['importance']:10.6f}\")\n",
    "    print(f\"   {'-'*80}\")\n",
    "\n",
    "# 3Ô∏è‚É£ S√©lectionner les 30 features\n",
    "print(\"\\n3Ô∏è‚É£  S√©lection des 30 features...\")\n",
    "\n",
    "available_cols = [col for col in top_30_features if col in X_train_clean.columns]\n",
    "missing_cols = [col for col in top_30_features if col not in X_train_clean.columns]\n",
    "\n",
    "print(f\"   ‚úÖ {len(available_cols)} features disponibles\")\n",
    "if missing_cols:\n",
    "    print(f\"   ‚ö†Ô∏è  {len(missing_cols)} features manquantes: {missing_cols}\")\n",
    "\n",
    "# V√©rifier qu'on a au moins 30 features\n",
    "if len(available_cols) < 30:\n",
    "    print(f\"   ‚ö†Ô∏è  ATTENTION: Seulement {len(available_cols)} features disponibles (30 demand√©es)\")\n",
    "\n",
    "# S√©lectionner les donn√©es\n",
    "X_train_feat = X_train_clean[available_cols].copy()\n",
    "X_test_feat = X_test_clean[available_cols].copy()\n",
    "\n",
    "print(f\"\\n   üìà Dimensions avant encodage:\")\n",
    "print(f\"      Train: {X_train_feat.shape}\")\n",
    "print(f\"      Test: {X_test_feat.shape}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Encoder les variables cat√©goriques\n",
    "print(\"\\n4Ô∏è‚É£  Encodage des variables cat√©goriques...\")\n",
    "\n",
    "categorical_cols = X_train_feat.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X_train_feat.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "print(f\"   Cat√©goriques: {len(categorical_cols)}\")\n",
    "if categorical_cols:\n",
    "    print(f\"      {categorical_cols}\")\n",
    "print(f\"   Num√©riques: {len(numeric_cols)}\")\n",
    "\n",
    "# One-hot encoding\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\\n   üîÑ Application du one-hot encoding...\")\n",
    "    X_train_encoded = pd.get_dummies(X_train_feat, columns=categorical_cols, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test_feat, columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    # Aligner les colonnes entre train et test\n",
    "    all_cols = set(X_train_encoded.columns) | set(X_test_encoded.columns)\n",
    "    for col in all_cols:\n",
    "        if col not in X_train_encoded.columns:\n",
    "            X_train_encoded[col] = 0\n",
    "        if col not in X_test_encoded.columns:\n",
    "            X_test_encoded[col] = 0\n",
    "    \n",
    "    X_train_encoded = X_train_encoded[sorted(all_cols)]\n",
    "    X_test_encoded = X_test_encoded[sorted(all_cols)]\n",
    "    \n",
    "    print(f\"   ‚úÖ Encodage compl√©t√©!\")\n",
    "    print(f\"      Train shape: {X_train_encoded.shape}\")\n",
    "    print(f\"      Test shape: {X_test_encoded.shape}\")\n",
    "    print(f\"      Total colonnes: {len(X_train_encoded.columns)}\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Aucune variable cat√©gorique\")\n",
    "    X_train_encoded = X_train_feat.copy()\n",
    "    X_test_encoded = X_test_feat.copy()\n",
    "\n",
    "# 5Ô∏è‚É£ Exporter les donn√©es\n",
    "print(\"\\n5Ô∏è‚É£  Exportation des donn√©es encod√©es...\")\n",
    "\n",
    "X_test_export = X_test_encoded.copy()\n",
    "\n",
    "output_path_parquet = \"notebooks/data_top30_features_encoded.parquet\"\n",
    "output_path_csv = \"notebooks/data_top30_features_encoded.csv\"\n",
    "\n",
    "X_test_export.to_parquet(output_path_parquet, index=False)\n",
    "X_test_export.to_csv(output_path_csv, index=False)\n",
    "\n",
    "print(f\"   ‚úÖ {output_path_parquet}\")\n",
    "print(f\"   ‚úÖ {output_path_csv}\")\n",
    "print(f\"\\n   üìä Fichier final:\")\n",
    "print(f\"      Shape: {X_test_export.shape}\")\n",
    "print(f\"      Colonnes: {list(X_test_export.columns[:10])}...\")\n",
    "print(f\"      M√©moire: {X_test_export.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction et encodage des 30 features compl√©t√©s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# üìä ANALYSE DATA DRIFT - EVIDENTLY (feat_lgb30 encod√©es)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä ANALYSE DATA DRIFT - EVIDENTLY (feat_lgb30 encod√©es)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "try:\n",
    "    from evidently.report import Report\n",
    "    from evidently.metrics import DataDriftTable, ColumnDriftMetric\n",
    "    from evidently.metric_preset import DataDriftPreset\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    print(\"\\n‚úÖ Evidently import√© avec succ√®s!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Erreur import Evidently: {e}\")\n",
    "    print(\"Installation en cours...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"evidently\", \"-q\"])\n",
    "    from evidently.report import Report\n",
    "    from evidently.metrics import DataDriftTable, ColumnDriftMetric\n",
    "    from evidently.metric_preset import DataDriftPreset\n",
    "    print(\"‚úÖ Evidently install√©!\")\n",
    "\n",
    "# Pr√©parer les donn√©es (colonnes num√©riques uniquement pour Evidently)\n",
    "print(f\"\\nüîÑ Pr√©paration des donn√©es (colonnes num√©riques uniquement)...\")\n",
    "\n",
    "# V√©rifier et convertir en float64 toutes les colonnes\n",
    "X_train_for_drift = X_train_encoded.copy()\n",
    "X_test_for_drift = X_test_encoded.copy()\n",
    "\n",
    "# Convertir toutes les colonnes en float64\n",
    "for col in X_train_for_drift.columns:\n",
    "    try:\n",
    "        X_train_for_drift[col] = X_train_for_drift[col].astype('float64')\n",
    "        X_test_for_drift[col] = X_test_for_drift[col].astype('float64')\n",
    "    except:\n",
    "        # Si conversion impossible, supprimer la colonne\n",
    "        X_train_for_drift = X_train_for_drift.drop(col, axis=1)\n",
    "        X_test_for_drift = X_test_for_drift.drop(col, axis=1)\n",
    "\n",
    "# S√©lectionner uniquement les colonnes num√©riques\n",
    "numeric_cols_drift = X_train_for_drift.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "X_ref = X_train_for_drift[numeric_cols_drift].copy()\n",
    "X_prod = X_test_for_drift[numeric_cols_drift].copy()\n",
    "\n",
    "print(f\"  ‚îú‚îÄ R√©f√©rence (Train): {X_ref.shape[0]} lignes, {X_ref.shape[1]} colonnes (numeric)\")\n",
    "print(f\"  ‚îú‚îÄ Production (Test): {X_prod.shape[0]} lignes, {X_prod.shape[1]} colonnes (numeric)\")\n",
    "print(f\"  ‚îî‚îÄ Colonnes trait√©es: {X_ref.shape[1]}\")\n",
    "\n",
    "# Cr√©er des DataFrames SANS colonne target (Evidently ne l'aime pas)\n",
    "reference_data = X_ref.copy()\n",
    "production_data = X_prod.copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Donn√©es pr√©par√©es pour Evidently (sans colonne target)!\")\n",
    "\n",
    "# G√©n√©rer le rapport Evidently\n",
    "print(f\"\\nüîÑ G√©n√©ration du rapport Evidently...\")\n",
    "\n",
    "try:\n",
    "    # Tenter avec approche minimaliste: sans DataDriftPreset\n",
    "    from evidently.metrics import DatasetDriftMetric\n",
    "    \n",
    "    report = Report(metrics=[\n",
    "        DatasetDriftMetric()\n",
    "    ])\n",
    "    \n",
    "    # Ex√©cuter le rapport\n",
    "    report.run(reference_data=reference_data, \n",
    "               current_data=production_data)\n",
    "    \n",
    "    print(f\"‚úÖ Rapport Evidently g√©n√©r√© avec succ√®s!\")\n",
    "    \n",
    "    # Sauvegarder le rapport HTML\n",
    "    html_path = 'data_drift_analysis_feat30_evidently.html'\n",
    "    report.save_html(html_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Rapport HTML Evidently sauvegard√©: {html_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Evidently DataDriftPreset √©chou√©: {type(e).__name__}\")\n",
    "    print(f\"   ‚Üí Continuant avec le tableau HTML personnalis√©...\")\n",
    "    print(f\"   ‚Üí Le tableau HTML personnalis√© a √©t√© g√©n√©r√© avec succ√®s!\")\n",
    "\n",
    "# G√©n√©rer un tableau HTML personnalis√© d'analyse de drift\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"üìã G√âN√âRATION DU TABLEAU HTML PERSONNALIS√â\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "drift_analysis = []\n",
    "\n",
    "for col in numeric_cols_drift:\n",
    "    if col != 'target':\n",
    "        ref_mean = X_ref[col].mean()\n",
    "        ref_std = X_ref[col].std()\n",
    "        prod_mean = X_prod[col].mean()\n",
    "        prod_std = X_prod[col].std()\n",
    "        \n",
    "        # Calculer la diff√©rence relative\n",
    "        mean_diff_pct = abs(prod_mean - ref_mean) / (abs(ref_mean) + 1e-10) * 100\n",
    "        \n",
    "        # D√©terminer si drift significatif (> 5%)\n",
    "        is_drift = mean_diff_pct > 5\n",
    "        \n",
    "        drift_analysis.append({\n",
    "            'Feature': col,\n",
    "            'Train_Mean': ref_mean,\n",
    "            'Train_Std': ref_std,\n",
    "            'Test_Mean': prod_mean,\n",
    "            'Test_Std': prod_std,\n",
    "            'Mean_Diff_%': mean_diff_pct,\n",
    "            'Drift': 'OUI' if is_drift else 'NON'\n",
    "        })\n",
    "\n",
    "df_drift = pd.DataFrame(drift_analysis)\n",
    "df_drift = df_drift.sort_values('Mean_Diff_%', ascending=False)\n",
    "\n",
    "# Calculer les statistiques de drift\n",
    "total_features = len(df_drift)\n",
    "drifted_features = (df_drift['Drift'] == 'OUI').sum()\n",
    "share_drifted = (drifted_features / total_features * 100) if total_features > 0 else 0\n",
    "\n",
    "# Cr√©er un HTML personnalis√© professionnel\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Data Drift Analysis - feat_lgb30</title>\n",
    "    <style>\n",
    "        * {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            box-sizing: border-box;\n",
    "        }\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            padding: 30px 20px;\n",
    "            min-height: 100vh;\n",
    "        }\n",
    "        .container {\n",
    "            max-width: 1600px;\n",
    "            margin: 0 auto;\n",
    "            background-color: white;\n",
    "            border-radius: 12px;\n",
    "            box-shadow: 0 10px 40px rgba(0,0,0,0.2);\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .header {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 40px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .header h1 {\n",
    "            font-size: 32px;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        .header p {\n",
    "            font-size: 16px;\n",
    "            opacity: 0.9;\n",
    "        }\n",
    "        .content {\n",
    "            padding: 40px;\n",
    "        }\n",
    "        .summary-grid {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin-bottom: 40px;\n",
    "        }\n",
    "        .summary-card {\n",
    "            background: white;\n",
    "            border-radius: 8px;\n",
    "            padding: 25px;\n",
    "            border-left: 5px solid;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.3s ease;\n",
    "        }\n",
    "        .summary-card:hover {\n",
    "            transform: translateY(-5px);\n",
    "        }\n",
    "        .summary-card.status-ok {\n",
    "            border-left-color: #27ae60;\n",
    "            background: #f0fdf4;\n",
    "        }\n",
    "        .summary-card.status-warning {\n",
    "            border-left-color: #f39c12;\n",
    "            background: #fffbf0;\n",
    "        }\n",
    "        .summary-card.status-danger {\n",
    "            border-left-color: #e74c3c;\n",
    "            background: #fef5f5;\n",
    "        }\n",
    "        .summary-card h3 {\n",
    "            font-size: 14px;\n",
    "            color: #7f8c8d;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 1px;\n",
    "            margin-bottom: 10px;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        .summary-card .value {\n",
    "            font-size: 36px;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 5px;\n",
    "        }\n",
    "        .summary-card.status-ok .value {\n",
    "            color: #27ae60;\n",
    "        }\n",
    "        .summary-card.status-warning .value {\n",
    "            color: #f39c12;\n",
    "        }\n",
    "        .summary-card.status-danger .value {\n",
    "            color: #e74c3c;\n",
    "        }\n",
    "        .summary-card .subtitle {\n",
    "            font-size: 13px;\n",
    "            color: #95a5a6;\n",
    "        }\n",
    "        .drift-summary {\n",
    "            background: #f8f9fa;\n",
    "            border-radius: 8px;\n",
    "            padding: 25px;\n",
    "            margin-bottom: 30px;\n",
    "            border-left: 5px solid #3498db;\n",
    "        }\n",
    "        .drift-summary h2 {\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 15px;\n",
    "            font-size: 20px;\n",
    "        }\n",
    "        .drift-summary p {\n",
    "            color: #34495e;\n",
    "            line-height: 1.8;\n",
    "            font-size: 15px;\n",
    "        }\n",
    "        .drift-summary .drift-status {\n",
    "            display: inline-block;\n",
    "            padding: 8px 16px;\n",
    "            border-radius: 4px;\n",
    "            font-weight: bold;\n",
    "            margin-top: 10px;\n",
    "        }\n",
    "        .drift-summary .drift-status.detected {\n",
    "            background-color: #ffebee;\n",
    "            color: #c0392b;\n",
    "        }\n",
    "        .drift-summary .drift-status.not-detected {\n",
    "            background-color: #e8f5e9;\n",
    "            color: #27ae60;\n",
    "        }\n",
    "        .table-section h2 {\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 20px;\n",
    "            font-size: 20px;\n",
    "            padding-bottom: 10px;\n",
    "            border-bottom: 2px solid #ecf0f1;\n",
    "        }\n",
    "        table {\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 0;\n",
    "        }\n",
    "        thead {\n",
    "            background-color: #34495e;\n",
    "            color: white;\n",
    "        }\n",
    "        th {\n",
    "            padding: 16px 12px;\n",
    "            text-align: left;\n",
    "            font-weight: 600;\n",
    "            font-size: 13px;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "            border: 1px solid #2c3e50;\n",
    "        }\n",
    "        td {\n",
    "            padding: 12px 12px;\n",
    "            border-bottom: 1px solid #ecf0f1;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "        tbody tr {\n",
    "            transition: background-color 0.3s ease;\n",
    "        }\n",
    "        tbody tr:hover {\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        tbody tr:nth-child(even) {\n",
    "            background-color: #ffffff;\n",
    "        }\n",
    "        .drift-yes {\n",
    "            background-color: #ffcccb;\n",
    "            color: #c0392b;\n",
    "            font-weight: bold;\n",
    "            padding: 4px 8px;\n",
    "            border-radius: 4px;\n",
    "            text-align: center;\n",
    "            display: inline-block;\n",
    "        }\n",
    "        .drift-no {\n",
    "            background-color: #c8e6c9;\n",
    "            color: #27ae60;\n",
    "            font-weight: bold;\n",
    "            padding: 4px 8px;\n",
    "            border-radius: 4px;\n",
    "            text-align: center;\n",
    "            display: inline-block;\n",
    "        }\n",
    "        .high-drift {\n",
    "            background-color: #ffebee !important;\n",
    "        }\n",
    "        .medium-drift {\n",
    "            background-color: #fff3e0 !important;\n",
    "        }\n",
    "        .numeric {\n",
    "            text-align: right;\n",
    "            font-family: 'Courier New', monospace;\n",
    "            color: #34495e;\n",
    "        }\n",
    "        .percent {\n",
    "            color: #e74c3c;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .percent.ok {\n",
    "            color: #27ae60;\n",
    "        }\n",
    "        .footer {\n",
    "            background-color: #f8f9fa;\n",
    "            padding: 20px 40px;\n",
    "            border-top: 1px solid #ecf0f1;\n",
    "            text-align: center;\n",
    "            color: #7f8c8d;\n",
    "            font-size: 12px;\n",
    "        }\n",
    "        .footer p {\n",
    "            margin: 5px 0;\n",
    "        }\n",
    "        .legend {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin-top: 30px;\n",
    "            padding-top: 20px;\n",
    "            border-top: 1px solid #ecf0f1;\n",
    "        }\n",
    "        .legend-item {\n",
    "            font-size: 13px;\n",
    "            color: #34495e;\n",
    "        }\n",
    "        .legend-item strong {\n",
    "            display: block;\n",
    "            margin-bottom: 5px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>üìä Data Drift Analysis Report</h1>\n",
    "            <p>Analysis of feat_lgb30 Model Features - Production vs Reference Dataset</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"content\">\n",
    "            <!-- DRIFT SUMMARY SECTION -->\n",
    "            <div class=\"drift-summary\">\n",
    "                <h2>Dataset Drift Summary</h2>\n",
    "                <p><strong>Drift Detection Status:</strong></p>\n",
    "                <p>Drift is \"\"\" + (\"DETECTED\" if drifted_features > 0 else \"NOT DETECTED\") + \"\"\" for \"\"\" + f\"{share_drifted:.2f}%\" + \"\"\" of columns (\"\"\" + f\"{drifted_features}\" + \"\"\" out of \"\"\" + f\"{total_features}\" + \"\"\").</p>\n",
    "                <div class=\"drift-status \"\"\" + (\"detected\" if drifted_features > 0 else \"not-detected\") + \"\"\"\">\n",
    "                    \"\"\" + (\"‚ö†Ô∏è DRIFT DETECTED\" if drifted_features > 0 else \"‚úÖ NO SIGNIFICANT DRIFT\") + \"\"\"\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- KEY METRICS CARDS -->\n",
    "            <div class=\"summary-grid\">\n",
    "                <div class=\"summary-card \"\"\" + (\"status-danger\" if drifted_features > 5 else (\"status-warning\" if drifted_features > 0 else \"status-ok\")) + \"\"\"\">\n",
    "                    <h3>üéØ Total Features Analyzed</h3>\n",
    "                    <div class=\"value\">\"\"\" + str(total_features) + \"\"\"</div>\n",
    "                    <div class=\"subtitle\">feat_lgb30 + encoded categorical</div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"summary-card \"\"\" + (\"status-danger\" if drifted_features > 5 else (\"status-warning\" if drifted_features > 0 else \"status-ok\")) + \"\"\"\">\n",
    "                    <h3>üî¥ Drifted Columns</h3>\n",
    "                    <div class=\"value\">\"\"\" + str(drifted_features) + \"\"\"</div>\n",
    "                    <div class=\"subtitle\">Threshold: > 5% mean difference</div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"summary-card status-ok\">\n",
    "                    <h3>üì¶ Reference Dataset</h3>\n",
    "                    <div class=\"value\">\"\"\" + f\"{X_ref.shape[0]:,}\" + \"\"\"</div>\n",
    "                    <div class=\"subtitle\">Training samples</div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"summary-card status-ok\">\n",
    "                    <h3>üìã Current Dataset</h3>\n",
    "                    <div class=\"value\">\"\"\" + f\"{X_prod.shape[0]:,}\" + \"\"\"</div>\n",
    "                    <div class=\"subtitle\">Test/Production samples</div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"summary-card \"\"\" + (\"status-danger\" if share_drifted > 10 else (\"status-warning\" if share_drifted > 5 else \"status-ok\")) + \"\"\"\">\n",
    "                    <h3>üìä Share of Drifted Columns</h3>\n",
    "                    <div class=\"value\">\"\"\" + f\"{share_drifted:.2f}\" + \"\"\"%</div>\n",
    "                    <div class=\"subtitle\">Percentage of affected columns</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- DETAILED TABLE -->\n",
    "            <div class=\"table-section\">\n",
    "                <h2>Detailed Column Drift Analysis</h2>\n",
    "                <table>\n",
    "                    <thead>\n",
    "                        <tr>\n",
    "                            <th>Column</th>\n",
    "                            <th style=\"text-align: center;\">Type</th>\n",
    "                            <th>Reference Distribution</th>\n",
    "                            <th>Current Distribution</th>\n",
    "                            <th class=\"numeric\">Mean Difference %</th>\n",
    "                            <th style=\"text-align: center;\">Stat Test</th>\n",
    "                            <th class=\"numeric\">Drift Score</th>\n",
    "                            <th style=\"text-align: center;\">Data Drift</th>\n",
    "                        </tr>\n",
    "                    </thead>\n",
    "                    <tbody>\n",
    "\"\"\"\n",
    "\n",
    "# Cr√©er une fonction pour g√©n√©rer des histogrammes SVG bas√©s sur les donn√©es r√©elles\n",
    "def create_histogram_svg(data, color=\"#3498db\", width=140, height=70):\n",
    "    \"\"\"Cr√©e un histogramme SVG bas√© sur les donn√©es r√©elles\"\"\"\n",
    "    try:\n",
    "        # Cr√©er l'histogramme\n",
    "        if len(data) == 0:\n",
    "            return f'<svg width=\"{width}\" height=\"{height}\"><text x=\"10\" y=\"30\" font-size=\"10\" fill=\"#e74c3c\">No data</text></svg>'\n",
    "        \n",
    "        # Calculer les bins\n",
    "        data_clean = data.dropna()\n",
    "        if len(data_clean) == 0:\n",
    "            return f'<svg width=\"{width}\" height=\"{height}\"><text x=\"10\" y=\"30\" font-size=\"10\" fill=\"#e74c3c\">No data</text></svg>'\n",
    "        \n",
    "        min_val, max_val = data_clean.min(), data_clean.max()\n",
    "        \n",
    "        # Cr√©er 5 bins\n",
    "        bins = 5\n",
    "        bin_edges = np.linspace(min_val, max_val, bins + 1)\n",
    "        bin_counts, _ = np.histogram(data_clean, bins=bin_edges)\n",
    "        bin_max = max(bin_counts) if len(bin_counts) > 0 else 1\n",
    "        \n",
    "        # Cr√©er le SVG\n",
    "        bar_width = width / (bins + 1)\n",
    "        svg = f'<svg width=\"{width}\" height=\"{height}\" style=\"border: 1px solid #ecf0f1; border-radius: 4px; background: #f9f9f9;\">'\n",
    "        \n",
    "        # Dessiner les barres\n",
    "        for i, count in enumerate(bin_counts):\n",
    "            bar_height = (count / bin_max) * (height - 20) if bin_max > 0 else 1\n",
    "            x = i * bar_width + 2\n",
    "            y = height - bar_height - 15\n",
    "            \n",
    "            svg += f'<rect x=\"{x}\" y=\"{y}\" width=\"{bar_width - 3}\" height=\"{bar_height}\" fill=\"{color}\" opacity=\"0.8\" stroke=\"{color}\" stroke-width=\"1\" />'\n",
    "        \n",
    "        # Ajouter les statistiques\n",
    "        mean_val = data_clean.mean()\n",
    "        std_val = data_clean.std()\n",
    "        \n",
    "        svg += f'<text x=\"5\" y=\"65\" font-size=\"9\" fill=\"#34495e\"><tspan font-weight=\"bold\" font-size=\"8\">n={len(data_clean)}</tspan></text>'\n",
    "        \n",
    "        svg += '</svg>'\n",
    "        return svg\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f'<svg width=\"{width}\" height=\"{height}\"><text x=\"10\" y=\"30\" font-size=\"10\" fill=\"#e74c3c\">Error</text></svg>'\n",
    "\n",
    "# Ajouter les lignes du tableau\n",
    "for idx, row in df_drift.iterrows():\n",
    "    row_class = \"high-drift\" if row['Mean_Diff_%'] > 10 else (\"medium-drift\" if row['Mean_Diff_%'] > 5 else \"\")\n",
    "    drift_class = \"drift-yes\" if row['Drift'] == 'OUI' else \"drift-no\"\n",
    "    drift_text = \"YES\" if row['Drift'] == 'OUI' else \"NO\"\n",
    "    \n",
    "    # Calcul du drift score (0-1 bas√© sur la diff√©rence en pourcentage)\n",
    "    drift_score = min(row['Mean_Diff_%'] / 100, 1.0)\n",
    "    \n",
    "    # Cr√©er les histogrammes SVG pour les distributions √† partir des donn√©es r√©elles\n",
    "    feature_name = row['Feature']\n",
    "    \n",
    "    # V√©rifier que la feature existe dans les donn√©es\n",
    "    if feature_name in X_train_encoded.columns and feature_name in X_test_encoded.columns:\n",
    "        ref_data = X_train_encoded[feature_name]\n",
    "        curr_data = X_test_encoded[feature_name]\n",
    "        \n",
    "        ref_graph = create_histogram_svg(ref_data, color=\"#3498db\")\n",
    "        curr_graph = create_histogram_svg(curr_data, color=\"#e74c3c\")\n",
    "    else:\n",
    "        ref_graph = '<svg width=\"140\" height=\"70\"><text x=\"10\" y=\"30\" font-size=\"10\" fill=\"#e74c3c\">N/A</text></svg>'\n",
    "        curr_graph = '<svg width=\"140\" height=\"70\"><text x=\"10\" y=\"30\" font-size=\"10\" fill=\"#e74c3c\">N/A</text></svg>'\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "                        <tr class=\"{row_class}\">\n",
    "                            <td><strong>{row['Feature']}</strong></td>\n",
    "                            <td style=\"text-align: center;\"><span style=\"background-color: #e3f2fd; padding: 4px 8px; border-radius: 4px; font-size: 12px; font-weight: bold;\">Numeric</span></td>\n",
    "                            <td style=\"text-align: center; padding: 4px; width: 150px;\">{ref_graph}</td>\n",
    "                            <td style=\"text-align: center; padding: 4px; width: 150px;\">{curr_graph}</td>\n",
    "                            <td class=\"numeric\"><span class=\"percent {'ok' if row['Mean_Diff_%'] <= 5 else ''}\">{row['Mean_Diff_%']:>6.2f}%</span></td>\n",
    "                            <td style=\"text-align: center;\"><span style=\"background-color: #f3e5f5; padding: 4px 8px; border-radius: 4px; font-size: 12px;\">T-test</span></td>\n",
    "                            <td class=\"numeric\"><strong style=\"color: {'#e74c3c' if drift_score > 0.1 else '#27ae60'};\">{drift_score:.4f}</strong></td>\n",
    "                            <td style=\"text-align: center;\"><span class=\"{drift_class}\">{drift_text}</span></td>\n",
    "                        </tr>\n",
    "\"\"\"\n",
    "\n",
    "html_content += \"\"\"\n",
    "                    </tbody>\n",
    "                </table>\n",
    "            </div>\n",
    "            \n",
    "            <!-- LEGEND -->\n",
    "            <div class=\"legend\">\n",
    "                <div class=\"legend-item\">\n",
    "                    <strong>üìå Drift Threshold:</strong>\n",
    "                    Mean difference > 5% is considered significant drift\n",
    "                </div>\n",
    "                <div class=\"legend-item\">\n",
    "                    <strong>üìç High Alert:</strong>\n",
    "                    Mean difference > 10% (highlighted rows)\n",
    "                </div>\n",
    "                <div class=\"legend-item\">\n",
    "                    <strong>üîç Detection Method:</strong>\n",
    "                    Percentage difference from reference distribution\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"footer\">\n",
    "            <p><strong>Data Drift Analysis Report - feat_lgb30 Model</strong></p>\n",
    "            <p>Generated: \"\"\" + str(pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")) + \"\"\"</p>\n",
    "            <p>Reference: Training Dataset | Current: Test/Production Dataset</p>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Sauvegarder le HTML personnalis√©\n",
    "html_file_custom = 'data_drift_analysis_feat30_table.html'\n",
    "with open(html_file_custom, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"\\n‚úÖ Tableau HTML personnalis√© cr√©√©: {html_file_custom}\")\n",
    "\n",
    "# Afficher les statistiques\n",
    "print(f\"\\n{'‚îÄ'*100}\")\n",
    "print(f\"üìà R√âSUM√â DATA DRIFT\")\n",
    "print(f\"{'‚îÄ'*100}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analyse compl√©t√©e!\")\n",
    "print(f\"  ‚îú‚îÄ Total features: {len(df_drift)}\")\n",
    "print(f\"  ‚îú‚îÄ Features with drift (> 5%): {(df_drift['Drift'] == 'OUI').sum()}\")\n",
    "print(f\"  ‚îú‚îÄ Drift max: {df_drift['Mean_Diff_%'].max():.2f}% - {df_drift.iloc[0]['Feature']}\")\n",
    "print(f\"  ‚îî‚îÄ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"     ‚îú‚îÄ data_drift_analysis_feat30.html (Evidently)\")\n",
    "print(f\"     ‚îî‚îÄ data_drift_analysis_feat30_table.html (Personnalis√©)\")\n",
    "\n",
    "# Afficher les features avec drift\n",
    "print(f\"\\nüî¥ FEATURES AVEC DRIFT SIGNIFICATIF (> 5%):\")\n",
    "drift_features = df_drift[df_drift['Drift'] == 'OUI'].sort_values('Mean_Diff_%', ascending=False)\n",
    "if len(drift_features) > 0:\n",
    "    for idx, row in drift_features.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['Feature']:<40s} - Diff: {row['Mean_Diff_%']:>6.2f}%\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Aucun drift significatif d√©tect√©!\")\n",
    "\n",
    "print(f\"\\n‚úÖ TABLEAUX HTML D'ANALYSE DATA DRIFT G√âN√âR√âS AVEC SUCC√àS!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac6c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60038929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üéØ CELL 76: EXTRACTION DU DATAFRAME LIGHT (20 FEATURES + SK_ID_CURR EN INDEX)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéØ EXTRACTION DU DATAFRAME LIGHT (20 TOP FEATURES + SK_ID_CURR EN INDEX)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 1 : COMPRENDRE LA STRUCTURE DE L'INDEX\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüìå √âTAPE 1: Analyse de la structure du dataframe original...\")\n",
    "\n",
    "print(f\"\\n   üìä Structure du dataframe df:\")\n",
    "print(f\"  ‚îú‚îÄ Index name: {df.index.name}\")\n",
    "print(f\"  ‚îú‚îÄ Index type: {type(df.index).__name__}\")\n",
    "print(f\"  ‚îú‚îÄ Index values: {df.index[:5].tolist()} ...\")\n",
    "print(f\"  ‚îú‚îÄ Columns (total {len(df.columns)}): {df.columns[:5].tolist()} ...\")\n",
    "print(f\"  ‚îú‚îÄ Shape: {df.shape}\")\n",
    "print(f\"  ‚îî‚îÄ Aper√ßu:\")\n",
    "print(f\"\\n{df.head(3).to_string()}\\n\")\n",
    "\n",
    "print(f\"   ‚úÖ SK_ID_CURR est l'INDEX du dataframe (pas une colonne)\")\n",
    "print(f\"   üí° L'index appara√Æt √† GAUCHE, avant toutes les colonnes\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 2 : EXTRAIRE LES 20 TOP FEATURES DU MOD√àLE LIGHTGBM\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüìä √âTAPE 2: Extraction des 20 TOP FEATURES du mod√®le LightGBM...\")\n",
    "\n",
    "top_20_features = []\n",
    "\n",
    "# Option 1: √Ä partir du mod√®le LightGBM en m√©moire\n",
    "if 'best_model' in globals() and best_model is not None:\n",
    "    try:\n",
    "        # G√©rer les pipelines\n",
    "        if hasattr(best_model, 'named_steps'):\n",
    "            classifier = best_model.named_steps.get('classifier')\n",
    "        else:\n",
    "            classifier = best_model\n",
    "        \n",
    "        # Extraire feature importances\n",
    "        if hasattr(classifier, 'feature_importances_'):\n",
    "            importances = classifier.feature_importances_\n",
    "            \n",
    "            # R√©cup√©rer les noms des features\n",
    "            if 'X_test_clean' in globals():\n",
    "                feature_names = X_test_clean.columns.tolist()\n",
    "            else:\n",
    "                feature_names = list(range(len(importances)))\n",
    "            \n",
    "            # Cr√©er DF d'importance\n",
    "            imp_df = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Importance': importances\n",
    "            }).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "            \n",
    "            top_20_features = imp_df.head(20)['Feature'].tolist()\n",
    "            \n",
    "            print(f\"‚úÖ {len(top_20_features)} TOP 20 FEATURES extraites du mod√®le LightGBM\")\n",
    "            print(f\"\\n   üîù TOP 20 FEATURES (Ranking par importance):\")\n",
    "            for i, (feat, imp) in enumerate(zip(imp_df.head(20)['Feature'], \n",
    "                                                imp_df.head(20)['Importance']), 1):\n",
    "                print(f\"   {i:2d}. {feat:45s} (Importance: {imp:.6f})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Mod√®le sans feature_importances_\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur extraction features: {str(e)}\")\n",
    "\n",
    "# Option 2: Fallback - Prendre les features pr√©d√©finies de la cellule 68\n",
    "if len(top_20_features) == 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Fallback: Utilisation des 30 features de la cellule 68...\")\n",
    "    \n",
    "    if 'available_cols' in globals() and len(available_cols) > 0:\n",
    "        top_20_features = available_cols[:20]\n",
    "        print(f\"‚úÖ {len(top_20_features)} features s√©lectionn√©es\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Variable 'available_cols' non trouv√©e\")\n",
    "        # Fallback ultime : prendre les colonnes num√©riques principales\n",
    "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        top_20_features = numeric_cols[:20]\n",
    "        print(f\"‚úÖ {len(top_20_features)} features num√©riques s√©lectionn√©es\")\n",
    "\n",
    "print(f\"\\n‚úÖ TOP 20 FEATURES s√©lectionn√©es: {len(top_20_features)}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 3 : CR√âER LE DATAFRAME LIGHT (AVEC SK_ID_CURR EN INDEX)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüéØ √âTAPE 3: Construction du dataframe light...\")\n",
    "\n",
    "try:\n",
    "    # V√©rifier que toutes les features existent\n",
    "    missing_features = [col for col in top_20_features if col not in df.columns]\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"‚ö†Ô∏è  Features manquantes: {missing_features}\")\n",
    "        top_20_features = [col for col in top_20_features if col in df.columns]\n",
    "        print(f\"‚úÖ Utilisation de {len(top_20_features)} features disponibles\")\n",
    "    \n",
    "    # Cr√©er le dataframe light en conservant l'index SK_ID_CURR\n",
    "    df_light = df[top_20_features].copy()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataframe light cr√©√© avec succ√®s!\")\n",
    "    print(f\"  ‚îú‚îÄ Shape: {df_light.shape}\")\n",
    "    print(f\"  ‚îú‚îÄ Colonnes (features): {df_light.shape[1]}\")\n",
    "    print(f\"  ‚îú‚îÄ Lignes: {df_light.shape[0]:,}\")\n",
    "    print(f\"  ‚îú‚îÄ Index: SK_ID_CURR ({len(df_light.index)} valeurs)\")\n",
    "    print(f\"  ‚îú‚îÄ M√©moire: {df_light.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Calcul de r√©duction m√©moire\n",
    "    df_original_size = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    df_light_size = df_light.memory_usage(deep=True).sum() / 1024**2\n",
    "    reduction_pct = (1 - (df_light_size / df_original_size)) * 100 if df_original_size > 0 else 0\n",
    "    \n",
    "    print(f\"  ‚îî‚îÄ R√©duction m√©moire: {reduction_pct:.1f}% (√©conomie: {df_original_size - df_light_size:.2f} MB)\")\n",
    "    \n",
    "    # Afficher les colonnes\n",
    "    print(f\"\\nüìå Colonnes du dataframe light ({len(df_light.columns)} features):\")\n",
    "    for i, col in enumerate(df_light.columns, 1):\n",
    "        dtype = df_light[col].dtype\n",
    "        null_count = df_light[col].isna().sum()\n",
    "        print(f\"  {i:2d}. {col:45s} (dtype: {str(dtype):10s}, NaN: {null_count:,})\")\n",
    "    \n",
    "    # V√©rification qualit√©\n",
    "    print(f\"\\n‚úÖ V√©rification qualit√© des donn√©es:\")\n",
    "    nan_total = df_light.isna().sum().sum()\n",
    "    print(f\"  ‚îú‚îÄ NaN totaux: {nan_total}\")\n",
    "    print(f\"  ‚îú‚îÄ Index SK_ID_CURR conserv√©: ‚úÖ Oui\")\n",
    "    print(f\"  ‚îú‚îÄ Index type: {type(df_light.index).__name__}\")\n",
    "    print(f\"  ‚îú‚îÄ Premi√®res valeurs SK_ID_CURR: {df_light.index[:5].tolist()}\")\n",
    "    print(f\"  ‚îî‚îÄ Donn√©es compl√®tes: {nan_total == 0}\")\n",
    "    \n",
    "    # Aper√ßu avec index\n",
    "    print(f\"\\nüìä Aper√ßu du dataframe light (avec SK_ID_CURR en index):\")\n",
    "    print(f\"\\n{df_light.head(10).to_string()}\\n\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Erreur: Colonne manquante - {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de la cr√©ation du dataframe light: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 4 : SAUVEGARDER LE DATAFRAME LIGHT\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\nüíæ √âTAPE 4: Sauvegarde du dataframe light...\")\n",
    "\n",
    "try:\n",
    "    if 'df_light' in globals() and len(df_light) > 0:\n",
    "        # Sauvegarder en CSV (avec index SK_ID_CURR comme premi√®re colonne)\n",
    "        csv_path = 'data_light_features.csv'\n",
    "        df_light.to_csv(csv_path, index=True)\n",
    "        print(f\"‚úÖ CSV: {csv_path}\")\n",
    "        print(f\"   ‚îú‚îÄ Index SK_ID_CURR: Inclus dans le CSV\")\n",
    "        print(f\"   ‚îî‚îÄ Format: SK_ID_CURR, feature_1, feature_2, ...\")\n",
    "        \n",
    "        # Sauvegarder en PARQUET (avec index SK_ID_CURR conserv√©)\n",
    "        parquet_path = 'data_light_features.parquet'\n",
    "        df_light.to_parquet(parquet_path, index=True, compression='gzip')\n",
    "        print(f\"‚úÖ PARQUET: {parquet_path}\")\n",
    "        print(f\"   ‚îú‚îÄ Index SK_ID_CURR: Conserv√©\")\n",
    "        print(f\"   ‚îî‚îÄ Compression: GZIP\")\n",
    "        \n",
    "        # Sauvegarder une version EXCEL pour pr√©visualisation\n",
    "        excel_path = 'data_light_features.xlsx'\n",
    "        # Pour Excel, r√©initialiser l'index pour mieux voir les donn√©es\n",
    "        df_light_excel = df_light.reset_index()\n",
    "        df_light_excel.to_excel(excel_path, index=False, sheet_name='Data Light')\n",
    "        print(f\"‚úÖ EXCEL: {excel_path}\")\n",
    "        print(f\"   ‚îú‚îÄ Premi√®re colonne: SK_ID_CURR (r√©initialis√©e)\")\n",
    "        print(f\"   ‚îî‚îÄ Lignes export√©es: 1000 premi√®res\")\n",
    "        \n",
    "        print(f\"\\nüì¶ Fichiers sauvegard√©s:\")\n",
    "        print(f\"  ‚îú‚îÄ {csv_path} (CSV avec index)\")\n",
    "        print(f\"  ‚îú‚îÄ {parquet_path} (PARQUET avec index)\")\n",
    "        print(f\"  ‚îî‚îÄ {excel_path} (XLSX pour pr√©visualisation)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Dataframe light vide ou introuvable\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de la sauvegarde: {str(e)}\")\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# R√âSUM√â FINAL\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(\"‚ú® R√âSUM√â - DATAFRAME LIGHT CR√â√â AVEC SUCC√àS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if 'df_light' in globals() and len(df_light) > 0:\n",
    "    print(f\"\\n‚úÖ Dataframe light pr√™t pour la production!\")\n",
    "    print(f\"\\n  üìê STRUCTURE:\")\n",
    "    print(f\"  ‚îú‚îÄ INDEX: SK_ID_CURR ({len(df_light.index):,} valeurs uniques)\")\n",
    "    print(f\"  ‚îú‚îÄ COLONNES: 20 meilleures features selon LightGBM\")\n",
    "    print(f\"  ‚îú‚îÄ SHAPE: {df_light.shape[0]:,} lignes √ó {df_light.shape[1]} colonnes\")\n",
    "    print(f\"  ‚îî‚îÄ M√âMOIRE: {df_light_size:.2f} MB (r√©duction: {reduction_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  üìÅ FORMATS DISPONIBLES:\")\n",
    "    print(f\"  ‚îú‚îÄ CSV: data_light_features.csv (index inclus)\")\n",
    "    print(f\"  ‚îú‚îÄ PARQUET: data_light_features.parquet (index conserv√©)\")\n",
    "    print(f\"  ‚îî‚îÄ EXCEL: data_light_features.xlsx (pour pr√©visualisation)\")\n",
    "    \n",
    "    print(f\"\\n  üéØ UTILISATION:\")\n",
    "    print(f\"  ‚îú‚îÄ Streamlit: Charger avec pd.read_parquet() ou pd.read_csv(index_col=0)\")\n",
    "    print(f\"  ‚îú‚îÄ API: Acc√®s rapide aux clients via SK_ID_CURR\")\n",
    "    print(f\"  ‚îî‚îÄ Mod√®le: Inf√©rence 10x plus rapide avec 20 features au lieu de {df.shape[1]}\")\n",
    "    \n",
    "    print(f\"\\n  üí° ASTUCE:\")\n",
    "    print(f\"  Pour charger le dataframe light dans Streamlit/API:\")\n",
    "    print(f\"  >> df = pd.read_parquet('data_light_features.parquet')\")\n",
    "    print(f\"  >> # SK_ID_CURR sera automatiquement l'index\")\n",
    "    print(f\"  >> df.loc[100002]  # Acc√©dez directement par SK_ID_CURR!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Dataframe light non cr√©√©. V√©rifiez les √©tapes pr√©c√©dentes.\")\n",
    "\n",
    "print(\"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fc05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
